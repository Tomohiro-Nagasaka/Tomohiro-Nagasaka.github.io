{"data":{"site":{"siteMetadata":{"title":"Tomo's Tech Notes","author":"Tomohiro Nagasaka","labels":[{"tag":"default","tech":"Default","name":"M 16.433594 23.824219 L 0.433594 12.824219 C 0.164062 12.636719 0 12.328125 0 12 C 0 11.671875 0.164062 11.363281 0.433594 11.175781 L 16.433594 0.175781 C 16.738281 -0.0351562 17.136719 -0.0585938 17.464844 0.117188 C 17.792969 0.289062 18 0.628906 18 1 L 18 23 C 18 23.371094 17.792969 23.710938 17.464844 23.882812 C 17.136719 24.058594 16.738281 24.035156 16.433594 23.824219 Z M 2.765625 12 L 16 21.097656 L 16 2.902344 Z M 2.765625 12 ","size":20,"color":"#0089D6"},{"tag":"tensorflow","tech":"Tensorflow","name":"M1.292 5.856L11.54 0v24l-4.095-2.378V7.603l-6.168 3.564.015-5.31zm21.43 5.311l-.014-5.31L12.46 0v24l4.095-2.378V14.87l3.092 1.788-.018-4.618-3.074-1.756V7.603l6.168 3.564z","size":20,"color":"#FF6F00"},{"tag":"keras","tech":"Keras","name":"M24 0H0v24h24V0zM8.45 5.16l.2.17v6.24l6.46-6.45h1.96l.2.4-5.14 5.1 5.47 7.94-.2.3h-1.94l-4.65-6.88-2.16 2.08v4.6l-.19.2H7l-.2-.2V5.33l.17-.17h1.48z","size":20,"color":"#D00000"},{"tag":"webapp","tech":"WebApp","name":"M12 0c6.623 0 12 5.377 12 12s-5.377 12-12 12S0 18.623 0 12 5.377 0 12 0zm3.279 17.68c-.766.441-1.029 1.422-.586 2.189.441.765 1.422 1.028 2.188.584.766-.441 1.029-1.422.585-2.189-.441-.765-1.421-1.028-2.187-.584zm-3.279-1c-.705 0-1.373-.157-1.971-.435L8.916 18.24c.93.459 1.978.721 3.084.721.646 0 1.268-.091 1.86-.256.104-.643.485-1.234 1.095-1.587.609-.351 1.313-.386 1.92-.156 1.186-1.163 1.957-2.749 2.07-4.515l-2.285-.033c-.21 2.391-2.215 4.266-4.66 4.266zM7.32 12c0-1.583.787-2.981 1.99-3.83L8.14 6.209c-1.404.93-2.445 2.369-2.881 4.035.506.404.83 1.034.83 1.74 0 .704-.324 1.319-.83 1.739.436 1.665 1.477 3.104 2.881 4.034l1.17-1.965C8.107 14.97 7.32 13.574 7.32 12zm-3.48-1.602c-.885 0-1.602.717-1.602 1.602s.717 1.602 1.602 1.602S5.441 12.885 5.441 12s-.716-1.602-1.601-1.602zM12 7.32c2.445 0 4.45 1.875 4.66 4.265l2.285-.034c-.113-1.765-.885-3.35-2.07-4.516-.609.232-1.313.194-1.92-.154-.609-.352-.99-.945-1.095-1.591-.594-.16-1.214-.25-1.86-.25-1.11 0-2.155.26-3.084.72l1.113 1.995c.6-.279 1.268-.435 1.971-.435zm3.279-1.001c.765.442 1.746.181 2.189-.585.441-.765.181-1.746-.588-2.19-.765-.44-1.746-.179-2.189.589-.441.764-.18 1.744.588 2.186z","size":20,"color":"#E95420"},{"tag":"cpp","tech":"C++","name":"M22.394 6c-.167-.29-.398-.543-.652-.69L12.926.22c-.509-.294-1.34-.294-1.848 0L2.26 5.31c-.508.293-.923 1.013-.923 1.6v10.18c0 .294.104.62.271.91.167.29.398.543.652.69l8.816 5.09c.508.293 1.34.293 1.848 0l8.816-5.09c.254-.147.485-.4.652-.69.167-.29.27-.616.27-.91V6.91c.003-.294-.1-.62-.268-.91zM12 19.11c-3.92 0-7.109-3.19-7.109-7.11 0-3.92 3.19-7.11 7.11-7.11a7.133 7.133 0 016.156 3.553l-3.076 1.78a3.567 3.567 0 00-3.08-1.78A3.56 3.56 0 008.444 12 3.56 3.56 0 0012 15.555a3.57 3.57 0 003.08-1.778l3.078 1.78A7.135 7.135 0 0112 19.11zm7.11-6.715h-.79v.79h-.79v-.79h-.79v-.79h.79v-.79h.79v.79h.79zm2.962 0h-.79v.79h-.79v-.79h-.79v-.79h.79v-.79h.79v.79h.79z","size":20,"color":"#00599C"},{"tag":"csharp","tech":"C#","name":"M12 0A12 12 0 000 12a12 12 0 0012 12 12 12 0 0012-12A12 12 0 0012 0zM9.426 7.12a5.55 5.55 0 011.985.38v1.181a4.5 4.5 0 00-2.25-.566 3.439 3.439 0 00-2.625 1.087 4.099 4.099 0 00-1.012 2.906 3.9 3.9 0 00.945 2.754 3.217 3.217 0 002.482 1.023 4.657 4.657 0 002.464-.634l-.004 1.08a5.543 5.543 0 01-2.625.555 4.211 4.211 0 01-3.228-1.297 4.793 4.793 0 01-1.212-3.409 5.021 5.021 0 011.365-3.663 4.631 4.631 0 013.473-1.392 5.55 5.55 0 01.12-.004 5.55 5.55 0 01.122 0zm5.863.155h.836l-.555 2.652h1.661l.567-2.652h.81l-.555 2.652 1.732-.004-.15.697H17.91l-.412 1.98h1.852l-.176.698h-1.816l-.58 2.625h-.83l.567-2.625h-1.65l-.555 2.625h-.81l.555-2.625h-1.74l.131-.698h1.748l.401-1.976h-1.826l.138-.697h1.826zm.142 3.345L15 12.6h1.673l.423-1.98z","size":20,"color":"#D239120"},{"tag":"react","tech":"React","name":"M12 9.861A2.139 2.139 0 1 0 12 14.139 2.139 2.139 0 1 0 12 9.861zM6.008 16.255l-.472-.12C2.018 15.246 0 13.737 0 11.996s2.018-3.25 5.536-4.139l.472-.119.133.468a23.53 23.53 0 0 0 1.363 3.578l.101.213-.101.213a23.307 23.307 0 0 0-1.363 3.578l-.133.467zM5.317 8.95c-2.674.751-4.315 1.9-4.315 3.046 0 1.145 1.641 2.294 4.315 3.046a24.95 24.95 0 0 1 1.182-3.046A24.752 24.752 0 0 1 5.317 8.95zM17.992 16.255l-.133-.469a23.357 23.357 0 0 0-1.364-3.577l-.101-.213.101-.213a23.42 23.42 0 0 0 1.364-3.578l.133-.468.473.119c3.517.889 5.535 2.398 5.535 4.14s-2.018 3.25-5.535 4.139l-.473.12zm-.491-4.259c.48 1.039.877 2.06 1.182 3.046 2.675-.752 4.315-1.901 4.315-3.046 0-1.146-1.641-2.294-4.315-3.046a24.788 24.788 0 0 1-1.182 3.046zM5.31 8.945l-.133-.467C4.188 4.992 4.488 2.494 6 1.622c1.483-.856 3.864.155 6.359 2.716l.34.349-.34.349a23.552 23.552 0 0 0-2.422 2.967l-.135.193-.235.02a23.657 23.657 0 0 0-3.785.61l-.472.119zm1.896-6.63c-.268 0-.505.058-.705.173-.994.573-1.17 2.565-.485 5.253a25.122 25.122 0 0 1 3.233-.501 24.847 24.847 0 0 1 2.052-2.544c-1.56-1.519-3.037-2.381-4.095-2.381zM16.795 22.677c-.001 0-.001 0 0 0-1.425 0-3.255-1.073-5.154-3.023l-.34-.349.34-.349a23.53 23.53 0 0 0 2.421-2.968l.135-.193.234-.02a23.63 23.63 0 0 0 3.787-.609l.472-.119.134.468c.987 3.484.688 5.983-.824 6.854a2.38 2.38 0 0 1-1.205.308zm-4.096-3.381c1.56 1.519 3.037 2.381 4.095 2.381h.001c.267 0 .505-.058.704-.173.994-.573 1.171-2.566.485-5.254a25.02 25.02 0 0 1-3.234.501 24.674 24.674 0 0 1-2.051 2.545zM18.69 8.945l-.472-.119a23.479 23.479 0 0 0-3.787-.61l-.234-.02-.135-.193a23.414 23.414 0 0 0-2.421-2.967l-.34-.349.34-.349C14.135 1.778 16.515.767 18 1.622c1.512.872 1.812 3.37.824 6.855l-.134.468zM14.75 7.24c1.142.104 2.227.273 3.234.501.686-2.688.509-4.68-.485-5.253-.988-.571-2.845.304-4.8 2.208A24.849 24.849 0 0 1 14.75 7.24zM7.206 22.677A2.38 2.38 0 0 1 6 22.369c-1.512-.871-1.812-3.369-.823-6.854l.132-.468.472.119c1.155.291 2.429.496 3.785.609l.235.02.134.193a23.596 23.596 0 0 0 2.422 2.968l.34.349-.34.349c-1.898 1.95-3.728 3.023-5.151 3.023zm-1.19-6.427c-.686 2.688-.509 4.681.485 5.254.987.563 2.843-.305 4.8-2.208a24.998 24.998 0 0 1-2.052-2.545 24.976 24.976 0 0 1-3.233-.501zM12 16.878c-.823 0-1.669-.036-2.516-.106l-.235-.02-.135-.193a30.388 30.388 0 0 1-1.35-2.122 30.354 30.354 0 0 1-1.166-2.228l-.1-.213.1-.213a30.3 30.3 0 0 1 1.166-2.228c.414-.716.869-1.43 1.35-2.122l.135-.193.235-.02a29.785 29.785 0 0 1 5.033 0l.234.02.134.193a30.006 30.006 0 0 1 2.517 4.35l.101.213-.101.213a29.6 29.6 0 0 1-2.517 4.35l-.134.193-.234.02c-.847.07-1.694.106-2.517.106zm-2.197-1.084c1.48.111 2.914.111 4.395 0a29.006 29.006 0 0 0 2.196-3.798 28.585 28.585 0 0 0-2.197-3.798 29.031 29.031 0 0 0-4.394 0 28.477 28.477 0 0 0-2.197 3.798 29.114 29.114 0 0 0 2.197 3.798z","size":20,"color":"deepskyblue"},{"tag":"nodejs","tech":"Node.js","name":"M11.177 25.3a1.94 1.94 0 0 1-.969-.259l-3.086-1.826c-.46-.257-.235-.349-.083-.402.614-.213.739-.262 1.394-.635.069-.038.159-.024.231.018l2.37 1.407a.304.304 0 0 0 .287 0l9.241-5.333a.292.292 0 0 0 .141-.25V7.355a.3.3 0 0 0-.143-.255l-9.237-5.329a.29.29 0 0 0-.285 0L1.803 7.102a.296.296 0 0 0-.146.253v10.666c0 .102.056.198.145.247l2.532 1.462c1.374.687 2.215-.122 2.215-.935V8.265c0-.149.12-.266.269-.266H7.99c.146 0 .267.117.267.266v10.53c0 1.833-.998 2.885-2.736 2.885-.534 0-.955 0-2.129-.579L.969 19.706A1.953 1.953 0 0 1 0 18.02V7.355c0-.693.371-1.339.969-1.684l9.242-5.34a2.023 2.023 0 0 1 1.942 0l9.241 5.34c.599.346.971.992.971 1.684V18.02c0 .693-.372 1.337-.971 1.686l-9.241 5.335a1.942 1.942 0 0 1-.973.259zm2.855-7.348c-4.045 0-4.892-1.857-4.892-3.414 0-.148.118-.266.266-.266h1.195c.133 0 .245.096.265.226.18 1.216.717 1.831 3.164 1.831 1.946 0 2.775-.441 2.775-1.473 0-.596-.234-1.037-3.26-1.334-2.528-.25-4.093-.809-4.093-2.831 0-1.865 1.572-2.977 4.207-2.977 2.961 0 4.425 1.027 4.611 3.233a.27.27 0 0 1-.267.291h-1.2a.266.266 0 0 1-.259-.209c-.288-1.28-.988-1.689-2.886-1.689-2.126 0-2.373.74-2.373 1.295 0 .673.292.869 3.161 1.248 2.84.375 4.19.907 4.19 2.902 0 2.014-1.678 3.167-4.606 3.167z","size":20,"color":"lightgreen"},{"tag":"git","tech":"Git","name":"M23.546 10.93L13.067.452c-.604-.603-1.582-.603-2.188 0L8.708 2.627l2.76 2.76c.645-.215 1.379-.07 1.889.441.516.515.658 1.258.438 1.9l2.658 2.66c.645-.223 1.387-.078 1.9.435.721.72.721 1.884 0 2.604-.719.719-1.881.719-2.6 0-.539-.541-.674-1.337-.404-1.996L12.86 8.955v6.525c.176.086.342.203.488.348.713.721.713 1.883 0 2.6-.719.721-1.889.721-2.609 0-.719-.719-.719-1.879 0-2.598.182-.18.387-.316.605-.406V8.835c-.217-.091-.424-.222-.6-.401-.545-.545-.676-1.342-.396-2.009L7.636 3.7.45 10.881c-.6.605-.6 1.584 0 2.189l10.48 10.477c.604.604 1.582.604 2.186 0l10.43-10.43c.605-.603.605-1.582 0-2.187","size":20,"color":"white"},{"tag":"javascript","tech":"JavaScript","name":"M0 0h24v24H0V0zm22.034 18.276c-.175-1.095-.888-2.015-3.003-2.873-.736-.345-1.554-.585-1.797-1.14-.091-.33-.105-.51-.046-.705.15-.646.915-.84 1.515-.66.39.12.75.42.976.9 1.034-.676 1.034-.676 1.755-1.125-.27-.42-.404-.601-.586-.78-.63-.705-1.469-1.065-2.834-1.034l-.705.089c-.676.165-1.32.525-1.71 1.005-1.14 1.291-.811 3.541.569 4.471 1.365 1.02 3.361 1.244 3.616 2.205.24 1.17-.87 1.545-1.966 1.41-.811-.18-1.26-.586-1.755-1.336l-1.83 1.051c.21.48.45.689.81 1.109 1.74 1.756 6.09 1.666 6.871-1.004.029-.09.24-.705.074-1.65l.046.067zm-8.983-7.245h-2.248c0 1.938-.009 3.864-.009 5.805 0 1.232.063 2.363-.138 2.711-.33.689-1.18.601-1.566.48-.396-.196-.597-.466-.83-.855-.063-.105-.11-.196-.127-.196l-1.825 1.125c.305.63.75 1.172 1.324 1.517.855.51 2.004.675 3.207.405.783-.226 1.458-.691 1.811-1.411.51-.93.402-2.07.397-3.346.012-2.054 0-4.109 0-6.179l.004-.056z","size":20,"color":"yellow"},{"tag":"css","tech":"CSS","name":"M1.5 0h21l-1.91 21.563L11.977 24l-8.565-2.438L1.5 0zm17.09 4.413L5.41 4.41l.213 2.622 10.125.002-.255 2.716h-6.64l.24 2.573h6.182l-.366 3.523-2.91.804-2.956-.81-.188-2.11h-2.61l.29 3.855L12 19.288l5.373-1.53L18.59 4.414z","size":20,"color":"teal"},{"tag":"python","tech":"Python","name":"M14.31.18l.9.2.73.26.59.3.45.32.34.34.25.34.16.33.1.3.04.26.02.2-.01.13V8.5l-.05.63-.13.55-.21.46-.26.38-.3.31-.33.25-.35.19-.35.14-.33.1-.3.07-.26.04-.21.02H8.83l-.69.05-.59.14-.5.22-.41.27-.33.32-.27.35-.2.36-.15.37-.1.35-.07.32-.04.27-.02.21v3.06H3.23l-.21-.03-.28-.07-.32-.12-.35-.18-.36-.26-.36-.36-.35-.46-.32-.59-.28-.73-.21-.88-.14-1.05L0 11.97l.06-1.22.16-1.04.24-.87.32-.71.36-.57.4-.44.42-.33.42-.24.4-.16.36-.1.32-.05.24-.01h.16l.06.01h8.16v-.83H6.24l-.01-2.75-.02-.37.05-.34.11-.31.17-.28.25-.26.31-.23.38-.2.44-.18.51-.15.58-.12.64-.1.71-.06.77-.04.84-.02 1.27.05 1.07.13zm-6.3 1.98l-.23.33-.08.41.08.41.23.34.33.22.41.09.41-.09.33-.22.23-.34.08-.41-.08-.41-.23-.33-.33-.22-.41-.09-.41.09-.33.22zM21.1 6.11l.28.06.32.12.35.18.36.27.36.35.35.47.32.59.28.73.21.88.14 1.04.05 1.23-.06 1.23-.16 1.04-.24.86-.32.71-.36.57-.4.45-.42.33-.42.24-.4.16-.36.09-.32.05-.24.02-.16-.01h-8.22v.82h5.84l.01 2.76.02.36-.05.34-.11.31-.17.29-.25.25-.31.24-.38.2-.44.17-.51.15-.58.13-.64.09-.71.07-.77.04-.84.01-1.27-.04-1.07-.14-.9-.2-.73-.25-.59-.3-.45-.33-.34-.34-.25-.34-.16-.33-.1-.3-.04-.25-.02-.2.01-.13v-5.34l.05-.64.13-.54.21-.46.26-.38.3-.32.33-.24.35-.2.35-.14.33-.1.3-.06.26-.04.21-.02.13-.01h5.84l.69-.05.59-.14.5-.21.41-.28.33-.32.27-.35.2-.36.15-.36.1-.35.07-.32.04-.28.02-.21V6.07h2.09l.14.01.21.03zm-6.47 14.25l-.23.33-.08.41.08.41.23.33.33.23.41.08.41-.08.33-.23.23-.33.08-.41-.08-.41-.23-.33-.33-.23-.41-.08-.41.08-.33.23z","size":20,"color":"deepskyblue"},{"tag":"ruby","tech":"Ruby","name":"M20.156.083c3.033.525 3.893 2.598 3.829 4.77L24 4.822 22.635 22.71 4.89 23.926h.016C3.433 23.864.15 23.729 0 19.139l1.645-3 2.819 6.586.503 1.172 2.805-9.144-.03.007.016-.03 9.255 2.956-1.396-5.431-.99-3.9 8.82-.569-.615-.51L16.5 2.114 20.159.073l-.003.01zM0 19.089v.026-.029.003zM5.13 5.073c3.561-3.533 8.157-5.621 9.922-3.84 1.762 1.777-.105 6.105-3.673 9.636-3.563 3.532-8.103 5.734-9.864 3.957-1.766-1.777.045-6.217 3.612-9.75l.003-.003z","size":20,"color":"crimson"},{"tag":"java","tech":"Java","name":"M8.851 18.56s-.917.534.653.714c1.902.218 2.874.187 4.969-.211 0 0 .552.346 1.321.646-4.699 2.013-10.633-.118-6.943-1.149M8.276 15.933s-1.028.761.542.924c2.032.209 3.636.227 6.413-.308 0 0 .384.389.987.602-5.679 1.661-12.007.13-7.942-1.218M13.116 11.475c1.158 1.333-.304 2.533-.304 2.533s2.939-1.518 1.589-3.418c-1.261-1.772-2.228-2.652 3.007-5.688 0-.001-8.216 2.051-4.292 6.573M19.33 20.504s.679.559-.747.991c-2.712.822-11.288 1.069-13.669.033-.856-.373.75-.89 1.254-.998.527-.114.828-.093.828-.093-.953-.671-6.156 1.317-2.643 1.887 9.58 1.553 17.462-.7 14.977-1.82M9.292 13.21s-4.362 1.036-1.544 1.412c1.189.159 3.561.123 5.77-.062 1.806-.152 3.618-.477 3.618-.477s-.637.272-1.098.587c-4.429 1.165-12.986.623-10.522-.568 2.082-1.006 3.776-.892 3.776-.892M17.116 17.584c4.503-2.34 2.421-4.589.968-4.285-.355.074-.515.138-.515.138s.132-.207.385-.297c2.875-1.011 5.086 2.981-.928 4.562 0-.001.07-.062.09-.118M14.401 0s2.494 2.494-2.365 6.33c-3.896 3.077-.888 4.832-.001 6.836-2.274-2.053-3.943-3.858-2.824-5.539 1.644-2.469 6.197-3.665 5.19-7.627M9.734 23.924c4.322.277 10.959-.153 11.116-2.198 0 0-.302.775-3.572 1.391-3.688.694-8.239.613-10.937.168 0-.001.553.457 3.393.639","size":20,"color":"wheat"},{"tag":"angular","tech":"Angular","name":"M9.93 12.645h4.134L11.996 7.74M11.996.009L.686 3.988l1.725 14.76 9.585 5.243 9.588-5.238L23.308 3.99 11.996.01zm7.058 18.297h-2.636l-1.42-3.501H8.995l-1.42 3.501H4.937l7.06-15.648 7.057 15.648z","size":20,"color":"red"},{"tag":"html","tech":"HTML","name":"M1.5 0h21l-1.91 21.563L11.977 24l-8.564-2.438L1.5 0zm7.031 9.75l-.232-2.718 10.059.003.23-2.622L5.412 4.41l.698 8.01h9.126l-.326 3.426-2.91.804-2.955-.81-.188-2.11H6.248l.33 4.171L12 19.351l5.379-1.443.744-8.157H8.531z","size":20,"color":"darkorange"},{"tag":"php","tech":"php","name":"M7.01 10.207h-.944l-.515 2.648h.838c.556 0 .97-.105 1.242-.314.272-.21.455-.559.55-1.049.092-.47.05-.802-.124-.995-.175-.193-.523-.29-1.047-.29zM12 5.688C5.373 5.688 0 8.514 0 12s5.373 6.313 12 6.313S24 15.486 24 12c0-3.486-5.373-6.312-12-6.312zm-3.26 7.451c-.261.25-.575.438-.917.551-.336.108-.765.164-1.285.164H5.357l-.327 1.681H3.652l1.23-6.326h2.65c.797 0 1.378.209 1.744.628.366.418.476 1.002.33 1.752a2.836 2.836 0 0 1-.305.847c-.143.255-.33.49-.561.703zm4.024.715l.543-2.799c.063-.318.039-.536-.068-.651-.107-.116-.336-.174-.687-.174H11.46l-.704 3.625H9.388l1.23-6.327h1.367l-.327 1.682h1.218c.767 0 1.295.134 1.586.401s.378.7.263 1.299l-.572 2.944h-1.389zm7.597-2.265a2.782 2.782 0 0 1-.305.847c-.143.255-.33.49-.561.703a2.44 2.44 0 0 1-.917.551c-.336.108-.765.164-1.286.164h-1.18l-.327 1.682h-1.378l1.23-6.326h2.649c.797 0 1.378.209 1.744.628.366.417.477 1.001.331 1.751zM17.766 10.207h-.943l-.516 2.648h.838c.557 0 .971-.105 1.242-.314.272-.21.455-.559.551-1.049.092-.47.049-.802-.125-.995s-.524-.29-1.047-.29z","size":20,"color":"violet"},{"tag":"mongodb","tech":"MongoDB","name":"M17.18 9.518c-1.263-5.56-4.242-7.387-4.562-8.086C12.266.939 11.885 0 11.885 0c-.002.019-.004.031-.005.049v.013h-.001c-.002.015-.003.025-.004.039v.015h-.002c0 .01-.002.018-.002.026v.026h-.003c-.001.008-.001.018-.003.025v.021h-.002c0 .007 0 .015-.002.021v.02h-.002c0 .01-.001.022-.002.032v.002c-.003.017-.006.034-.009.05v.008h-.002c-.001.004-.003.008-.003.012v.017h-.003v.022h-.005v.018h-.005v.021h-.004v.019h-.004v.017h-.006v.014h-.004v.018h-.004v.014h-.005v.013H11.8v.015h-.004c-.001.001-.001.003-.001.004v.01h-.003c-.001.002-.001.004-.001.006v.006h-.002c-.001.003-.002.008-.002.01-.003.007-.007.014-.01.021v.002c-.002.002-.004.005-.005.007v.008h-.004v.008h-.005v.008h-.003v.01h-.006v.014h-.004v.004h-.004v.008h-.004v.011h-.004v.008h-.006v.011h-.004v.008h-.005v.008h-.003v.01h-.005v.008h-.004v.006h-.004v.008h-.006V.76h-.004v.006h-.005v.008h-.004v.011h-.005v.004h-.003v.008h-.006v.004h-.004v.01h-.004v.004h-.004v.008h-.005v.006h-.003l-.002.004v.004h-.002c-.001.002-.002.002-.002.004v.001h-.001c-.001.003-.002.005-.004.007v.003h-.001c-.005.006-.008.012-.012.018v.001c-.002.002-.007.006-.009.01v.002h-.001c-.001.001-.003.002-.003.003v.003h-.002l-.003.003v.001h-.001c0 .001-.002.002-.003.004v.004h-.003l-.002.002v.002h-.002c0 .002-.002.002-.002.003v.003h-.004c0 .001-.001.002-.002.003V.92h-.003v.004h-.004V.93h-.004v.008h-.005V.93h-.005v.004h-.004V.94h-.005v.008h-.005v.004h-.004v.006h-.004v.004h-.004V.97h-.006v.004h-.004V.98h-.005v.004h-.004v.005h-.005v.01h-.002v.004h-.006v.005h-.004v.002h-.004v.004h-.005v.01h-.004v.004h-.005v.004h-.004v.006h-.005v.004h-.005v.004h-.004v.004h-.004v.01h-.004v.005h-.006v.004h-.004v.004h-.005v.006h-.004v.004h-.005v.007h-.004v.004h-.006V1.1h-.002v.004h-.004v.004h-.005v.004h-.004v.006h-.005v.004h-.003c-.001.001-.001.002-.001.002v.002h-.002l-.004.004s-.002.002-.004.003v.006h-.004v.005h-.004v.004h-.004v.004h-.003l-.003.003v.003h-.002l-.002.002v.003h-.002c-.005.006-.007.01-.014.016-.002.002-.008.007-.012.01-.012.008-.027.021-.039.032-.008.005-.016.012-.022.017v.001h-.001c-.016.013-.031.025-.049.039v.001c-.024.02-.047.039-.074.062V1.34h-.002c-.057.047-.117.1-.186.159V1.5h-.001c-.169.148-.37.338-.595.568l-.015.015-.004.004C9 3.494 6.857 6.426 6.631 11.164c-.02.392-.016.773.006 1.144v.009c.109 1.867.695 3.461 1.428 4.756v.001c.292.516.607.985.926 1.405v.001c1.102 1.455 2.227 2.317 2.514 2.526.441 1.023.4 2.779.4 2.779l.644.215s-.131-1.701.053-2.522c.057-.257.192-.476.349-.662.106-.075.42-.301.797-.645.018-.019.028-.036.044-.054 1.521-1.418 4.362-4.91 3.388-10.599z","size":20,"color":"green"},{"tag":"vscode","tech":"VS Code","name":"M23.15 2.587L18.21.21a1.494 1.494 0 0 0-1.705.29l-9.46 8.63-4.12-3.128a.999.999 0 0 0-1.276.057L.327 7.261A1 1 0 0 0 .326 8.74L3.899 12 .326 15.26a1 1 0 0 0 .001 1.479L1.65 17.94a.999.999 0 0 0 1.276.057l4.12-3.128 9.46 8.63a1.492 1.492 0 0 0 1.704.29l4.942-2.377A1.5 1.5 0 0 0 24 20.06V3.939a1.5 1.5 0 0 0-.85-1.352zm-5.146 14.861L10.826 12l7.178-5.448v10.896z","size":20,"color":"deepskyblue"},{"tag":"graphql","tech":"GraphQL","name":"M14.051 2.751l4.935 2.85c.816-.859 2.173-.893 3.032-.077.148.14.274.301.377.477.589 1.028.232 2.339-.796 2.928-.174.1-.361.175-.558.223v5.699c1.146.273 1.854 1.423 1.58 2.569-.048.204-.127.4-.232.581-.592 1.023-1.901 1.374-2.927.782-.196-.113-.375-.259-.526-.429l-4.905 2.832c.372 1.124-.238 2.335-1.361 2.706-.217.071-.442.108-.67.108-1.181.001-2.139-.955-2.14-2.136 0-.205.029-.41.088-.609l-4.936-2.847c-.816.854-2.171.887-3.026.07-.854-.816-.886-2.171-.07-3.026.283-.297.646-.506 1.044-.603l.001-5.699c-1.15-.276-1.858-1.433-1.581-2.584.047-.198.123-.389.224-.566.592-1.024 1.902-1.374 2.927-.782.177.101.339.228.48.377l4.938-2.85C9.613 1.612 10.26.423 11.39.088 11.587.029 11.794 0 12 0c1.181-.001 2.139.954 2.14 2.134.001.209-.03.418-.089.617zm-.515.877c-.019.021-.037.039-.058.058l6.461 11.19c.026-.009.056-.016.082-.023V9.146c-1.145-.283-1.842-1.442-1.558-2.588.006-.024.012-.049.019-.072l-4.946-2.858zm-3.015.059l-.06-.06-4.946 2.852c.327 1.135-.327 2.318-1.461 2.645-.026.008-.051.014-.076.021v5.708l.084.023 6.461-11.19-.002.001zm2.076.507c-.39.112-.803.112-1.192 0l-6.46 11.189c.294.283.502.645.6 1.041h12.911c.097-.398.307-.761.603-1.044L12.597 4.194zm.986 16.227l4.913-2.838c-.015-.047-.027-.094-.038-.142H5.542l-.021.083 4.939 2.852c.388-.404.934-.653 1.54-.653.627 0 1.19.269 1.583.698z","size":20,"color":"hotpink"},{"tag":"gatsby","tech":"Gatsby","name":"M12.001.007C5.326.007.007 5.326.007 12S5.326 23.995 12 23.995s11.994-5.319 11.994-11.994S18.676.007 12.001.007zM2.614 12.105l9.283 9.283c-5.111 0-9.283-4.172-9.283-9.283zm11.473 9.074L2.823 9.915C3.76 5.743 7.516 2.614 12 2.614a9.476 9.476 0 0 1 7.614 3.86L18.259 7.62a7.657 7.657 0 0 0-6.362-3.337A7.555 7.555 0 0 0 4.7 9.393l9.804 9.805c2.4-.835 4.276-2.92 4.798-5.424h-4.068v-1.773h6.154c0 4.485-3.129 8.24-7.301 9.178z","size":20,"color":"rebeccapurple"}]}},"allMarkdownRemark":{"totalCount":33,"edges":[{"node":{"excerpt":"Caffe\nKeras","html":"<p>Caffe\nKeras</p>","id":"06c2223d-e769-5ca3-9bf1-728f2a0973ac","frontmatter":{"title":"","date":null,"tags":["What I did","中文"]},"fields":{"slug":"/Chinese/What I did/Deep Learning/"}}},{"node":{"excerpt":"Kinect\nUnity\nUnreal Engine\nWireshark\nOculusCard Game\nMotioncapture Demo\nStereo tracking Demo","html":"<p>Kinect\nUnity\nUnreal Engine\nWireshark\nOculus</p>\n<p>Card Game\nMotioncapture Demo\nStereo tracking Demo</p>","id":"0c96726d-ee1f-5af5-a899-ebb2dfa767af","frontmatter":{"title":"","date":null,"tags":["What I did","中文"]},"fields":{"slug":"/Chinese/What I did/VR-Games/"}}},{"node":{"excerpt":"VICON\nOptitrack\nOpenSim\nBullet\nphysics simulation","html":"<p>VICON\nOptitrack\nOpenSim\nBullet\nphysics simulation</p>","id":"3fd1aefc-40c1-545c-8168-41990795c28c","frontmatter":{"title":"","date":null,"tags":["What I did","中文"]},"fields":{"slug":"/Chinese/What I did/Motion Capture/"}}},{"node":{"excerpt":"Photogrametry\nRealsense\nZEDOpenCV\nCUDA\nCalibration\nHalidePhotoshop Plugin","html":"<p>Photogrametry\nRealsense\nZED</p>\n<p>OpenCV\nCUDA\nCalibration\nHalide</p>\n<p>Photoshop Plugin</p>","id":"6e58e027-d2dd-5869-8ce0-a1a4799e2852","frontmatter":{"title":"","date":null,"tags":["What I did","中文"]},"fields":{"slug":"/Chinese/What I did/Computer Vision/"}}},{"node":{"excerpt":"Serenium\nChromiumLMDB\nLevelDB\nMySQLRaspberry Pi\nJetson Nano","html":"<p>Serenium\nChromium</p>\n<p>LMDB\nLevelDB\nMySQL</p>\n<p>Raspberry Pi\nJetson Nano</p>","id":"dbaf5229-7ad0-5c12-9ce1-e16767bee057","frontmatter":{"title":"","date":null,"tags":["What I did","中文"]},"fields":{"slug":"/Chinese/What I did/Others/"}}},{"node":{"excerpt":"","html":"","id":"9cf1a3a8-e575-5fc1-b8c3-9f67af6e25fd","frontmatter":{"title":"D4PG","date":"January 31, 2021","tags":["强化学习","中文"]},"fields":{"slug":"/Chinese/Reinforcement Learning/D4PG/"}}},{"node":{"excerpt":"D4PGD4PG解说从强化学习的理论基础到D4PG之类的比较新的做法。Q learningDeep Q learningActor, CliticDDPGT3Dtarget policy smoothingclipped double-Q learning\nD4PG","html":"<h1><a href=\"/D4PG\">D4PG</a></h1>\n<p><a href=\"/D4PG\">D4PG</a></p>\n<p>解说从强化学习的理论基础到D4PG之类的比较新的做法。</p>\n<h1>Q learning</h1>\n<h1>Deep Q learning</h1>\n<h1>Actor, Clitic</h1>\n<h1>DDPG</h1>\n<h1>T3D</h1>\n<ul>\n<li>target policy smoothing</li>\n<li>clipped double-Q learning\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 359px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/0d44a0e3fdb00c1594de1e0a51629dbd/412d9/Basics-2021-01-31-08-54-29.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 8.07799442896936%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAACCAIAAADXZGvcAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAADElEQVQI12NgGCgAAAB6AAFxCtNrAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Basics 2021 01 31 08 54 29\"\n        title=\"Basics 2021 01 31 08 54 29\"\n        src=\"/static/0d44a0e3fdb00c1594de1e0a51629dbd/412d9/Basics-2021-01-31-08-54-29.png\"\n        srcset=\"/static/0d44a0e3fdb00c1594de1e0a51629dbd/9ec3c/Basics-2021-01-31-08-54-29.png 200w,\n/static/0d44a0e3fdb00c1594de1e0a51629dbd/412d9/Basics-2021-01-31-08-54-29.png 359w\"\n        sizes=\"(max-width: 359px) 100vw, 359px\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 624px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/9c3ec0aa3f5b7d8f6a71f3c5fab9e2c4/857ee/Basics-2021-01-31-08-53-06.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 121.47435897435899%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAYCAIAAAB1KUohAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAAFElEQVQ4y2NgGAWjYBSMglEwlAAABbgAAb1K6ZMAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Basics 2021 01 31 08 53 06\"\n        title=\"Basics 2021 01 31 08 53 06\"\n        src=\"/static/9c3ec0aa3f5b7d8f6a71f3c5fab9e2c4/857ee/Basics-2021-01-31-08-53-06.png\"\n        srcset=\"/static/9c3ec0aa3f5b7d8f6a71f3c5fab9e2c4/9ec3c/Basics-2021-01-31-08-53-06.png 200w,\n/static/9c3ec0aa3f5b7d8f6a71f3c5fab9e2c4/c7805/Basics-2021-01-31-08-53-06.png 400w,\n/static/9c3ec0aa3f5b7d8f6a71f3c5fab9e2c4/857ee/Basics-2021-01-31-08-53-06.png 624w\"\n        sizes=\"(max-width: 624px) 100vw, 624px\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<h1>D4PG</h1>","id":"a772d0e9-81c0-5fdc-8ca2-f27ce0d51d23","frontmatter":{"title":"强化学习基础","date":"January 31, 2021","tags":["强化学习","中文","tensorflow"]},"fields":{"slug":"/Chinese/Reinforcement Learning/Basics/"}}},{"node":{"excerpt":"Stereo CameraSingle Camera2D Version2D Version with part segmentation","html":"<h2>Stereo Camera</h2>\n\n          <div\n            class=\"gatsby-resp-iframe-wrapper\"\n            style=\"padding-bottom: 56.25%; position: relative; height: 0; overflow: hidden;\"\n          >\n            <iframe src=\"https://www.youtube.com/embed/geaey9PhlTY\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen style=\"\n            position: absolute;\n            top: 0;\n            left: 0;\n            width: 100%;\n            height: 100%;\n          \"></iframe>\n          </div>\n          \n<hr>\n<h2>Single Camera</h2>\n\n          <div\n            class=\"gatsby-resp-iframe-wrapper\"\n            style=\"padding-bottom: 56.25%; position: relative; height: 0; overflow: hidden;\"\n          >\n            <iframe src=\"https://www.youtube.com/embed/3bh91gdcKvE\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen style=\"\n            position: absolute;\n            top: 0;\n            left: 0;\n            width: 100%;\n            height: 100%;\n          \"></iframe>\n          </div>\n          \n<hr>\n<h2>2D Version</h2>\n\n          <div\n            class=\"gatsby-resp-iframe-wrapper\"\n            style=\"padding-bottom: 56.25%; position: relative; height: 0; overflow: hidden;\"\n          >\n            <iframe src=\"https://www.youtube.com/embed/aifVZNJ2gG8\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen style=\"\n            position: absolute;\n            top: 0;\n            left: 0;\n            width: 100%;\n            height: 100%;\n          \"></iframe>\n          </div>\n          \n<hr>\n<h2>2D Version with part segmentation</h2>\n\n          <div\n            class=\"gatsby-resp-iframe-wrapper\"\n            style=\"padding-bottom: 56.25%; position: relative; height: 0; overflow: hidden;\"\n          >\n            <iframe src=\"https://www.youtube.com/embed/YHJRHgVeUI8\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen style=\"\n            position: absolute;\n            top: 0;\n            left: 0;\n            width: 100%;\n            height: 100%;\n          \"></iframe>\n          </div>\n          ","id":"3f2bc6bc-0b67-5b1f-940a-c060e86be835","frontmatter":{"title":"Hand Tracking","date":"January 30, 2021","tags":["Demo","Video","Featured"]},"fields":{"slug":"/Demo/HandTracking/"}}},{"node":{"excerpt":"","html":"","id":"6a8a5a2c-e05a-593e-927c-880bd7172da3","frontmatter":{"title":"Face Tracking/Morphing","date":"January 30, 2021","tags":["Demo","Video","Featured"]},"fields":{"slug":"/Demo/Face/"}}},{"node":{"excerpt":"","html":"","id":"9da2e98e-0921-5e95-a66d-3874f24350f1","frontmatter":{"title":"Physics Simulator","date":"January 30, 2021","tags":["Demo","Video","Featured"]},"fields":{"slug":"/Demo/PhysicsSimulator/"}}},{"node":{"excerpt":"Online Demohttp://tomo.asia/demo/","html":"<h1>Online Demo</h1>\n<p><a href=\"http://tomo.asia/demo/\">http://tomo.asia/demo/</a></p>","id":"c3de6ec9-8f17-5569-9ad8-482d5c9f0689","frontmatter":{"title":"Text To Speech","date":"January 30, 2021","tags":["Demo","Video","Featured","nodejs","cpp","python","webapp","electron","android","tensorflow"]},"fields":{"slug":"/Demo/TextToSpeech/"}}},{"node":{"excerpt":"","html":"","id":"45749084-a253-586d-9f5b-239799442e2c","frontmatter":{"title":"Pose Tracking","date":"January 30, 2021","tags":["Demo","Video","Featured"]},"fields":{"slug":"/Demo/PoseTracking/"}}},{"node":{"excerpt":"Website, Blogwordpress\nhugo\ngatsbyWeb appcakephp\ndjango\nflask\nASP.Net + Entity FrameworkServerapache\nnginx\nGit server\nVPN server\nLicense serverNetworkSocket Programming (C#, python, C++)","html":"<h1>Website, Blog</h1>\n<p>wordpress\nhugo\ngatsby</p>\n<h1>Web app</h1>\n<p>cakephp\ndjango\nflask\nASP.Net + Entity Framework</p>\n<h1>Server</h1>\n<p>apache\nnginx\nGit server\nVPN server\nLicense server</p>\n<h1>Network</h1>\n<p>Socket Programming (C#, python, C++)</p>","id":"ba1eb26f-4a4e-5ace-bbdd-196e7ae71a33","frontmatter":{"title":"Mobile/Web","date":"January 30, 2021","tags":["What I did","中文","android","webapp","nodejs","python"]},"fields":{"slug":"/Chinese/What I did/Mobile-Web/"}}},{"node":{"excerpt":"Blender\nMeshlab\nOpenGL\nWebGL","html":"<p>Blender\nMeshlab\nOpenGL\nWebGL</p>","id":"26d2cf26-e5be-54f2-ad16-ad97479df18b","frontmatter":{"title":"Mobile/Web","date":"January 30, 2021","tags":["What I did","中文","android","webapp","nodejs","python"]},"fields":{"slug":"/Chinese/What I did/3D Graphics/"}}},{"node":{"excerpt":"","html":"","id":"c7daf0a6-1a48-52ee-896b-5553484514a8","frontmatter":{"title":"Install","date":"January 30, 2021","tags":["gatsby","中文"]},"fields":{"slug":"/Chinese/gatsby/Install/"}}},{"node":{"excerpt":"中国ではElectronのダウンロードが異様に遅い。。。なんかエラーが出てもう一回インストールしろと言われる。\nスクリプトを走らせるだけで直った。npm run simpleserver'''\nnpm install --global --production windows-build-tools\nnode js gyp err cant find python executable…","html":"<p>中国ではElectronのダウンロードが異様に遅い。。。</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">set ELECTRON_MIRROR=https://npm.taobao.org/mirrors/electron/\nnpm install .</code></pre></div>\n<p>なんかエラーが出てもう一回インストールしろと言われる。\nスクリプトを走らせるだけで直った。</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">D:\\DEV\\monaco-editor-samples\\electron-amd&gt;electron .\nC:\\Users\\a\\AppData\\Roaming\\npm\\node_modules\\electron\\index.js:14\n    throw new Error(&#39;Electron failed to install correctly, please delete node_modules/electron and try installing again&#39;)\n    ^\n\nError: Electron failed to install correctly, please delete node_modules/electron and try installing again\n    at getElectronPath (C:\\Users\\a\\AppData\\Roaming\\npm\\node_modules\\electron\\index.js:14:11)\n    at Object.&lt;anonymous&gt; (C:\\Users\\a\\AppData\\Roaming\\npm\\node_modules\\electron\\index.js:18:18)\n    at Module._compile (internal/modules/cjs/loader.js:1133:30)\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:1153:10)\n    at Module.load (internal/modules/cjs/loader.js:977:32)\n    at Function.Module._load (internal/modules/cjs/loader.js:877:14)\n    at Module.require (internal/modules/cjs/loader.js:1019:19)\n    at require (internal/modules/cjs/helpers.js:77:18)\n    at Object.&lt;anonymous&gt; (C:\\Users\\a\\AppData\\Roaming\\npm\\node_modules\\electron\\cli.js:3:16)\n    at Module._compile (internal/modules/cjs/loader.js:1133:30)\n\nD:\\DEV\\monaco-editor-samples\\electron-amd&gt;node C:\\Users\\a\\AppData\\Roaming\\npm\\node_modules\\electron\\install.js       \n\nD:\\DEV\\monaco-editor-samples\\electron-amd&gt;electron .</code></pre></div>\n<p>npm run simpleserver</p>\n<p>'''\nnpm install --global --production windows-build-tools\nnode js gyp err cant find python executable windows\nInstall node-gyp globally as admin using the following command:\nnpm install node-gyp\n'''</p>","id":"ddf080dc-7ece-5b4c-88e7-2bbd90ba09c2","frontmatter":{"title":"セットアップ","date":"May 10, 2020","tags":["nodejs","日本語"]},"fields":{"slug":"/Japanese/nodejs/Electron1/"}}},{"node":{"excerpt":"インストールnano ~/.config/syncthing/config.xmlリモート","html":"<h2>インストール</h2>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"># Add the release PGP keys:\n# Add the &quot;stable&quot; channel to your APT sources:\n\ncurl -s https://syncthing.net/release-key.txt | sudo apt-key add -\necho &quot;deb https://apt.syncthing.net/ syncthing stable&quot; | sudo tee /etc/apt/sources.list.d/syncthing.list\nsudo apt-get update\nsudo apt-get install syncthing</code></pre></div>\n<p>nano ~/.config/syncthing/config.xml</p>\n<h2>リモート</h2>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">&lt;gui enabled=&quot;true&quot; tls=&quot;false&quot;&gt;\n    &lt;address&gt;127.0.0.1:8080&lt;/address&gt;\n&lt;/gui&gt;\n\n&gt;&gt;&gt;\n\n&lt;gui enabled=&quot;true&quot; tls=&quot;false&quot;&gt;\n    &lt;address&gt;0.0.0.0:8080&lt;/address&gt;\n&lt;/gui&gt;</code></pre></div>","id":"8b8af3c3-d35c-5da0-a170-6114193d09e0","frontmatter":{"title":"Syncthing","date":"May 04, 2020","tags":["webapp","日本語"]},"fields":{"slug":"/Japanese/webapp/ファイル同期/"}}},{"node":{"excerpt":"日本国内ではXサーバーが有名ですが、海外にも格安サーバーはたくさんあります。おすすめは下の二つ。HostwindsVultr時間単位で料金が発生。一番安いプランは月々500円。使わないときはサーバーの内容を凍結しておけば料金が発生しません。お財布に優しい。月々500円でLinux…","html":"<p>日本国内ではXサーバーが有名ですが、海外にも格安サーバーはたくさんあります。</p>\n<p>おすすめは下の二つ。</p>\n<h1>Hostwinds</h1>\n<h1>Vultr</h1>\n<p>時間単位で料金が発生。一番安いプランは月々500円。使わないときはサーバーの内容を凍結しておけば料金が発生しません。</p>\n<p>お財布に優しい。</p>\n<p>月々500円でLinuxサーバーが自由に使えます。</p>\n<p>プログラミングやシステム開発の勉強にも適しています。\n昔であれば自宅にサーバーを立てたりしましたが、現在はそんな必要もありません。</p>\n<p>Vultrは非常に使いやすいですが、中国からのアクセスは安定しません。\nSSHが結構ブロックされます。</p>","id":"cc8a63ce-a986-5afd-be30-7365d17656d2","frontmatter":{"title":"ホスティングサービス","date":"April 28, 2020","tags":["webapp","日本語"]},"fields":{"slug":"/Japanese/webapp/ホスティングサービス/"}}},{"node":{"excerpt":"環境作成現在のフォルダにインストールされることに注意。環境起動作成されたフォルダにあるactivate.batを使う。pip install pyinstaller\npyinstaller yourprogram.pypython --versionpip install imguiglfw########################################This is what I…","html":"<h2>環境作成</h2>\n<p>現在のフォルダにインストールされることに注意。</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">python <span class=\"token operator\">-</span>m venv myenvname</code></pre></div>\n<h2>環境起動</h2>\n<p>作成されたフォルダにあるactivate.batを使う。</p>\n<p>pip install pyinstaller\npyinstaller yourprogram.py</p>\n<p>python --version</p>\n<p>pip install imgui[glfw]</p>\n<p>########################################</p>\n<p>This is what I've added to the .spec file</p>\n<p>a.datas += [('images/icon.ico', 'D:\\[workspace]\\App\\src\\images\\icon.ico',  'DATA'),\n('images/loaderani.gif','D:\\[workspace]\\App\\src\\images\\loaderani.gif','DATA')]<br>\nI should add that I have tried not putting them in subfolders as well, didn't make a difference.</p>\n<p>139</p>\n<p>Newer versions of PyInstaller do not set the env variable anymore, so Shish's excellent answer will not work. Now the path gets set as sys._MEIPASS:</p>\n<p>def resource<em>path(relative</em>path):\n\"\"\" Get absolute path to resource, works for dev and for PyInstaller \"\"\"\ntry:\n# PyInstaller creates a temp folder and stores path in <em>MEIPASS\nbase</em>path = sys.<em>MEIPASS\nexcept Exception:\nbase</em>path = os.path.abspath(\".\")</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">return os.path.join(base_path, relative_path)</code></pre></div>\n<p>########################################</p>\n<p>  Create a directory structure like this:</p>\n<ul>\n<li>main.py  # Your code goes here - don't bother actually naming you file this</li>\n<li>\n<p>hooks</p>\n<ul>\n<li>hook-tensorflow.py\nCopy the following into hook-tensorflow.py:</li>\n</ul>\n</li>\n</ul>\n<p>from PyInstaller.utils.hooks import collect_all</p>\n<p>def hook(hook<em>api):\npackages = [\n'tensorflow',\n'tensorflow</em>core',\n'astor'\n]\nfor package in packages:\ndatas, binaries, hiddenimports = collect<em>all(package)\nhook</em>api.add<em>datas(datas)\nhook</em>api.add<em>binaries(binaries)\nhook</em>api.add_imports(*hiddenimports)\nThen, when compiling, add the command line option --additional-hooks-dir=hooks.</p>\n<p>If you come across more not fou</p>\n<p>########################################\nTensorboard</p>\n<p>12</p>\n<p>GIT: how to merge two branches without actually merging files (trivial merge)</p>\n<p>Use git merge -s ours B to perform a merge discarding any changes B would introduce. Still, the commits from B are now in A, however, the files are at the state of A before the merge.</p>","id":"76bbf56f-13c0-59a7-a0eb-e8a77a94da0f","frontmatter":{"title":"Virtualenv","date":"April 21, 2020","tags":["python","日本語"]},"fields":{"slug":"/Japanese/python/共通2/"}}},{"node":{"excerpt":"Tensorflow Addonバグがある？\nhttps://github.com/tensorflow/tensorflow/issues/20067Examplehttps://colab.research.google.com/github/dhirensk/ai/blob/master/EnglishtoFrenchseq2seqtf20_withAttention.ipynb","html":"<h2>Tensorflow Addon</h2>\n<p>バグがある？\n<a href=\"https://github.com/tensorflow/tensorflow/issues/20067\">https://github.com/tensorflow/tensorflow/issues/20067</a></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\nphysical_devices <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>config<span class=\"token punctuation\">.</span>list_physical_devices<span class=\"token punctuation\">(</span><span class=\"token string\">'GPU'</span><span class=\"token punctuation\">)</span>\ntf<span class=\"token punctuation\">.</span>config<span class=\"token punctuation\">.</span>experimental<span class=\"token punctuation\">.</span>set_memory_growth<span class=\"token punctuation\">(</span>physical_devices<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> enable<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h2>Example</h2>\n<p><a href=\"https://colab.research.google.com/github/dhirensk/ai/blob/master/English_to_French_seq2seq_tf_2_0_withAttention.ipynb\">https://colab.research.google.com/github/dhirensk/ai/blob/master/English<em>to</em>French<em>seq2seq</em>tf<em>2</em>0_withAttention.ipynb</a></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\">#ENCODER</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">EncoderNetwork</span><span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>input_vocab_size<span class=\"token punctuation\">,</span>embedding_dims<span class=\"token punctuation\">,</span> rnn_units <span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>encoder_embedding <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Embedding<span class=\"token punctuation\">(</span>input_dim<span class=\"token operator\">=</span>input_vocab_size<span class=\"token punctuation\">,</span>\n                                                           output_dim<span class=\"token operator\">=</span>embedding_dims<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>encoder_rnnlayer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>LSTM<span class=\"token punctuation\">(</span>rnn_units<span class=\"token punctuation\">,</span>return_sequences<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> \n                                                     return_state<span class=\"token operator\">=</span><span class=\"token boolean\">True</span> <span class=\"token punctuation\">)</span>\n    \n<span class=\"token comment\">#DECODER</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">DecoderNetwork</span><span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>output_vocab_size<span class=\"token punctuation\">,</span> embedding_dims<span class=\"token punctuation\">,</span> rnn_units<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>decoder_embedding <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Embedding<span class=\"token punctuation\">(</span>input_dim<span class=\"token operator\">=</span>output_vocab_size<span class=\"token punctuation\">,</span>\n                                                           output_dim<span class=\"token operator\">=</span>embedding_dims<span class=\"token punctuation\">)</span> \n        self<span class=\"token punctuation\">.</span>dense_layer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span>output_vocab_size<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>decoder_rnncell <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>LSTMCell<span class=\"token punctuation\">(</span>rnn_units<span class=\"token punctuation\">)</span>\n        <span class=\"token comment\"># Sampler</span>\n        self<span class=\"token punctuation\">.</span>sampler <span class=\"token operator\">=</span> tfa<span class=\"token punctuation\">.</span>seq2seq<span class=\"token punctuation\">.</span>sampler<span class=\"token punctuation\">.</span>TrainingSampler<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        <span class=\"token comment\"># Create attention mechanism with memory = None</span>\n        self<span class=\"token punctuation\">.</span>attention_mechanism <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>build_attention_mechanism<span class=\"token punctuation\">(</span>dense_units<span class=\"token punctuation\">,</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span>BATCH_SIZE<span class=\"token operator\">*</span><span class=\"token punctuation\">[</span>Tx<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>rnn_cell <span class=\"token operator\">=</span>  self<span class=\"token punctuation\">.</span>build_rnn_cell<span class=\"token punctuation\">(</span>BATCH_SIZE<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>decoder <span class=\"token operator\">=</span> tfa<span class=\"token punctuation\">.</span>seq2seq<span class=\"token punctuation\">.</span>BasicDecoder<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>rnn_cell<span class=\"token punctuation\">,</span> sampler<span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>sampler<span class=\"token punctuation\">,</span>\n                                                output_layer<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>dense_layer<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">build_attention_mechanism</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> units<span class=\"token punctuation\">,</span>memory<span class=\"token punctuation\">,</span> memory_sequence_length<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> tfa<span class=\"token punctuation\">.</span>seq2seq<span class=\"token punctuation\">.</span>LuongAttention<span class=\"token punctuation\">(</span>units<span class=\"token punctuation\">,</span> memory <span class=\"token operator\">=</span> memory<span class=\"token punctuation\">,</span> \n                                          memory_sequence_length<span class=\"token operator\">=</span>memory_sequence_length<span class=\"token punctuation\">)</span>\n        <span class=\"token comment\">#return tfa.seq2seq.BahdanauAttention(units, memory = memory, memory_sequence_length=memory_sequence_length)</span>\n\n    <span class=\"token comment\"># wrap decodernn cell  </span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">build_rnn_cell</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> batch_size <span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        rnn_cell <span class=\"token operator\">=</span> tfa<span class=\"token punctuation\">.</span>seq2seq<span class=\"token punctuation\">.</span>AttentionWrapper<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>decoder_rnncell<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>attention_mechanism<span class=\"token punctuation\">,</span>\n                                                attention_layer_size<span class=\"token operator\">=</span>dense_units<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> rnn_cell\n    \n    <span class=\"token keyword\">def</span> <span class=\"token function\">build_decoder_initial_state</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> batch_size<span class=\"token punctuation\">,</span> encoder_state<span class=\"token punctuation\">,</span>Dtype<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        decoder_initial_state <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>rnn_cell<span class=\"token punctuation\">.</span>get_initial_state<span class=\"token punctuation\">(</span>batch_size <span class=\"token operator\">=</span> batch_size<span class=\"token punctuation\">,</span> \n                                                                dtype <span class=\"token operator\">=</span> Dtype<span class=\"token punctuation\">)</span>\n        decoder_initial_state <span class=\"token operator\">=</span> decoder_initial_state<span class=\"token punctuation\">.</span>clone<span class=\"token punctuation\">(</span>cell_state<span class=\"token operator\">=</span>encoder_state<span class=\"token punctuation\">)</span> \n        <span class=\"token keyword\">return</span> decoder_initial_state\n\n\n\nencoderNetwork <span class=\"token operator\">=</span> EncoderNetwork<span class=\"token punctuation\">(</span>input_vocab_size<span class=\"token punctuation\">,</span>embedding_dims<span class=\"token punctuation\">,</span> rnn_units<span class=\"token punctuation\">)</span>\ndecoderNetwork <span class=\"token operator\">=</span> DecoderNetwork<span class=\"token punctuation\">(</span>output_vocab_size<span class=\"token punctuation\">,</span>embedding_dims<span class=\"token punctuation\">,</span> rnn_units<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">loss_function</span><span class=\"token punctuation\">(</span>y_pred<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n   \n    <span class=\"token comment\">#shape of y [batch_size, ty]</span>\n    <span class=\"token comment\">#shape of y_pred [batch_size, Ty, output_vocab_size] </span>\n    sparsecategoricalcrossentropy <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>losses<span class=\"token punctuation\">.</span>SparseCategoricalCrossentropy<span class=\"token punctuation\">(</span>from_logits<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n                                                                                  reduction<span class=\"token operator\">=</span><span class=\"token string\">'none'</span><span class=\"token punctuation\">)</span>\n    loss <span class=\"token operator\">=</span> sparsecategoricalcrossentropy<span class=\"token punctuation\">(</span>y_true<span class=\"token operator\">=</span>y<span class=\"token punctuation\">,</span> y_pred<span class=\"token operator\">=</span>y_pred<span class=\"token punctuation\">)</span>\n    <span class=\"token comment\">#skip loss calculation for padding sequences i.e. y = 0 </span>\n    <span class=\"token comment\">#[ &lt;start>,How, are, you, today, 0, 0, 0, 0 ....&lt;end>]</span>\n    <span class=\"token comment\">#[ 1, 234, 3, 423, 3344, 0, 0 ,0 ,0, 2 ]</span>\n    <span class=\"token comment\"># y is a tensor of [batch_size,Ty] . Create a mask when [y=0]</span>\n    <span class=\"token comment\"># mask the loss when padding sequence appears in the output sequence</span>\n    mask <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>logical_not<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>math<span class=\"token punctuation\">.</span>equal<span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>   <span class=\"token comment\">#output 0 for y=0 else output 1</span>\n    mask <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>cast<span class=\"token punctuation\">(</span>mask<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>loss<span class=\"token punctuation\">.</span>dtype<span class=\"token punctuation\">)</span>\n    loss <span class=\"token operator\">=</span> mask<span class=\"token operator\">*</span> loss\n    loss <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>reduce_mean<span class=\"token punctuation\">(</span>loss<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> loss</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">train_step</span><span class=\"token punctuation\">(</span>input_batch<span class=\"token punctuation\">,</span> output_batch<span class=\"token punctuation\">,</span>encoder_initial_cell_state<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\">#initialize loss = 0</span>\n    loss <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n    <span class=\"token keyword\">with</span> tf<span class=\"token punctuation\">.</span>GradientTape<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> tape<span class=\"token punctuation\">:</span>\n        encoder_emb_inp <span class=\"token operator\">=</span> encoderNetwork<span class=\"token punctuation\">.</span>encoder_embedding<span class=\"token punctuation\">(</span>input_batch<span class=\"token punctuation\">)</span>\n        a<span class=\"token punctuation\">,</span> a_tx<span class=\"token punctuation\">,</span> c_tx <span class=\"token operator\">=</span> encoderNetwork<span class=\"token punctuation\">.</span>encoder_rnnlayer<span class=\"token punctuation\">(</span>encoder_emb_inp<span class=\"token punctuation\">,</span> \n                                                        initial_state <span class=\"token operator\">=</span>encoder_initial_cell_state<span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\">#[last step activations,last memory_state] of encoder passed as input to decoder Network</span>\n        \n         \n        <span class=\"token comment\"># Prepare correct Decoder input &amp; output sequence data</span>\n        decoder_input <span class=\"token operator\">=</span> output_batch<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">:</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token comment\"># ignore &lt;end></span>\n        <span class=\"token comment\">#compare logits with timestepped +1 version of decoder_input</span>\n        decoder_output <span class=\"token operator\">=</span> output_batch<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span> <span class=\"token comment\">#ignore &lt;start></span>\n\n\n        <span class=\"token comment\"># Decoder Embeddings</span>\n        decoder_emb_inp <span class=\"token operator\">=</span> decoderNetwork<span class=\"token punctuation\">.</span>decoder_embedding<span class=\"token punctuation\">(</span>decoder_input<span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\">#Setting up decoder memory from encoder output and Zero State for AttentionWrapperState</span>\n        decoderNetwork<span class=\"token punctuation\">.</span>attention_mechanism<span class=\"token punctuation\">.</span>setup_memory<span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">)</span>\n        decoder_initial_state <span class=\"token operator\">=</span> decoderNetwork<span class=\"token punctuation\">.</span>build_decoder_initial_state<span class=\"token punctuation\">(</span>BATCH_SIZE<span class=\"token punctuation\">,</span>\n                                                                           encoder_state<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>a_tx<span class=\"token punctuation\">,</span> c_tx<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                                                                           Dtype<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span>\n        \n        <span class=\"token comment\">#BasicDecoderOutput        </span>\n        outputs<span class=\"token punctuation\">,</span> _<span class=\"token punctuation\">,</span> _ <span class=\"token operator\">=</span> decoderNetwork<span class=\"token punctuation\">.</span>decoder<span class=\"token punctuation\">(</span>decoder_emb_inp<span class=\"token punctuation\">,</span>initial_state<span class=\"token operator\">=</span>decoder_initial_state<span class=\"token punctuation\">,</span>\n                                               sequence_length<span class=\"token operator\">=</span>BATCH_SIZE<span class=\"token operator\">*</span><span class=\"token punctuation\">[</span>Ty<span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n        logits <span class=\"token operator\">=</span> outputs<span class=\"token punctuation\">.</span>rnn_output\n        <span class=\"token comment\">#Calculate loss</span>\n\n        loss <span class=\"token operator\">=</span> loss_function<span class=\"token punctuation\">(</span>logits<span class=\"token punctuation\">,</span> decoder_output<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">#Returns the list of all layer variables / weights.</span>\n    variables <span class=\"token operator\">=</span> encoderNetwork<span class=\"token punctuation\">.</span>trainable_variables <span class=\"token operator\">+</span> decoderNetwork<span class=\"token punctuation\">.</span>trainable_variables  \n    <span class=\"token comment\"># differentiate loss wrt variables</span>\n    gradients <span class=\"token operator\">=</span> tape<span class=\"token punctuation\">.</span>gradient<span class=\"token punctuation\">(</span>loss<span class=\"token punctuation\">,</span> variables<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">#grads_and_vars – List of(gradient, variable) pairs.</span>\n    grads_and_vars <span class=\"token operator\">=</span> <span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span>gradients<span class=\"token punctuation\">,</span>variables<span class=\"token punctuation\">)</span>\n    optimizer<span class=\"token punctuation\">.</span>apply_gradients<span class=\"token punctuation\">(</span>grads_and_vars<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> loss</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\">#RNN LSTM hidden and memory state initializer</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">initialize_initial_state</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> <span class=\"token punctuation\">[</span>tf<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>BATCH_SIZE<span class=\"token punctuation\">,</span> rnn_units<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> tf<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>BATCH_SIZE<span class=\"token punctuation\">,</span> rnn_units<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n\nepochs <span class=\"token operator\">=</span> <span class=\"token number\">15</span>\n<span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n    encoder_initial_cell_state <span class=\"token operator\">=</span> initialize_initial_state<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    total_loss <span class=\"token operator\">=</span> <span class=\"token number\">0.0</span>\n\n\n    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span> batch <span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>input_batch<span class=\"token punctuation\">,</span> output_batch<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>dataset<span class=\"token punctuation\">.</span>take<span class=\"token punctuation\">(</span>steps_per_epoch<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        batch_loss <span class=\"token operator\">=</span> train_step<span class=\"token punctuation\">(</span>input_batch<span class=\"token punctuation\">,</span> output_batch<span class=\"token punctuation\">,</span> encoder_initial_cell_state<span class=\"token punctuation\">)</span>\n        total_loss <span class=\"token operator\">+=</span> batch_loss\n        <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>batch<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token operator\">%</span><span class=\"token number\">20</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"total loss: {} epoch {} batch {} \"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>batch_loss<span class=\"token punctuation\">.</span>numpy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> i<span class=\"token punctuation\">,</span> batch<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n            checkpoint<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span>file_prefix <span class=\"token operator\">=</span> chkpoint_prefix<span class=\"token punctuation\">)</span></code></pre></div>","id":"64b1bd03-09ad-53d7-91a8-75d5ffba886a","frontmatter":{"title":"Seq2Seq","date":"April 19, 2020","tags":["python","日本語"]},"fields":{"slug":"/Japanese/python/ディープラーニング1/"}}},{"node":{"excerpt":"GitNginx/etc/nginx/sites-available/default を編集する。location ~ /git(/.*) で /var/www/html/git以下にマッチさせる。設定ファイルの正当性チェック、再起動ユーザー追加ここではユーザー Tomoを追加します。\nコマンドを入力するとパスワードの設定を求められます。レポジトリ作成ここではblog…","html":"<h2>Git</h2>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">sudo apt-get install git</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">mkdir git\ncd git\ngit init --bare --shared blog.git</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">sudo mkdir /var/www/html/git\nsudo chown -R www-data:www-data /var/www/html/git</code></pre></div>\n<h2>Nginx</h2>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">sudo apt-get update\nsudo apt-get install nginx nano fcgiwrap apache2-utils -y</code></pre></div>\n<p>/etc/nginx/sites-available/default を編集する。</p>\n<p>location ~ /git(/.*) で /var/www/html/git以下にマッチさせる。</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">server {\n        listen 80 default_server;\n        listen [::]:80 default_server;\n\n\n        root /var/www/html/blog;\n\n        # Add index.php to the list if you are using PHP\n        index index.html index.htm index.nginx-debian.html;\n\n        server_name _;\n\n        location / {\n                # First attempt to serve request as file, then\n                # as directory, then fall back to displaying a 404.\n                try_files $uri $uri/ =404;\n        }\n\nlocation ~ /git(/.*) {\n    root /var/www/html;\n    client_max_body_size 0; # Git pushes can be massive, just to make sure nginx doesn&#39;t suddenly cut the connection add this.\n    auth_basic &quot;Git Login&quot;; # Whatever text will do.\n    auth_basic_user_file &quot;/var/www/html/git/htpasswd&quot;;\n    include /etc/nginx/fastcgi_params; # Include the default fastcgi configs\n    fastcgi_param SCRIPT_FILENAME /usr/lib/git-core/git-http-backend; # Tells fastcgi to pass the request to the git http backend executable\n    fastcgi_param GIT_HTTP_EXPORT_ALL &quot;&quot;;\n    fastcgi_param GIT_PROJECT_ROOT /var/www/html/git; # /var/www/git is the location of all of your git repositories.\n    fastcgi_param REMOTE_USER $remote_user;\n    fastcgi_param PATH_INFO $1; # Takes the capture group from our location directive and gives git that.\n    fastcgi_pass  unix:/var/run/fcgiwrap.socket; # Pass the request to fastcgi\n}\n\n}</code></pre></div>\n<h3>設定ファイルの正当性チェック、再起動</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">sudo nginx -t\nsudo systemctl restart nginx</code></pre></div>\n<h3>ユーザー追加</h3>\n<p>ここではユーザー Tomoを追加します。\nコマンドを入力するとパスワードの設定を求められます。</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">sudo htpasswd -c /var/www/html/git/htpasswd Tomo</code></pre></div>\n<h3>レポジトリ作成</h3>\n<p>ここではblogレポジトリを作成します</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">cd /var/www/html/git\nsudo mkdir blog.git\nsudo cd blog.git\nsudo git --bare init\nsudo git update-server-info\nsudo chown -R www-data.www-data .\nsudo chmod -R 755 .</code></pre></div>\n<h3>ファイアウォール</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">sudo ufw enable\nsudo ufw allow http\nsudo ufw allow ssh</code></pre></div>\n<h3>Nginx</h3>\n<p>ps aux | grep [n]ginx | awk '{ print \"kill -9\", $2 }'\nsudo kill -9 <code class=\"language-text\">sudo lsof -t -i:80</code>\nsudo systemctl restart nginx</p>\n<h3>Clone</h3>\n<p>cd /var/www/html\ngit clone ./git/blog.git</p>\n<p>リモートからアクセスする場合は：</p>\n<p>git clone <a href=\"http://Tomo@142.11.211.91/git/blog.git\">http://Tomo@142.11.211.91/git/blog.git</a></p>\n<h3>コミットテスト</h3>\n<p>git add .\ngit commit -m \"test commit\"\ngit push origin master</p>\n<h3>ハードリセット</h3>\n<p>git reset --hard origin/master</p>\n<h3>プロキシ</h3>\n<p>.gitconfigに追加</p>\n<p>[http]\nproxy = <a href=\"http://127.0.0.1:50174\">http://127.0.0.1:50174</a>\n[https]\nproxy = <a href=\"http://127.0.0.1:50174\">http://127.0.0.1:50174</a></p>","id":"ba5313a9-2bfd-55da-a5ab-153a552cd38e","frontmatter":{"title":"Gitサーバー","date":"April 11, 2020","tags":["webapp","日本語"]},"fields":{"slug":"/Japanese/webapp/Gitサーバー/"}}},{"node":{"excerpt":"https://github.com/gohugoio/hugoGoHugo注意：SCSSを使うには”Extended”版が必要GitHook/var/www/html/git/blog.git/hooks/post-receive を作成bash /var/www/html/git/blog.git/hooks/post-receive\nで動作確認Hugo Nginx/etc/nginx…","html":"<p><a href=\"https://github.com/gohugoio/hugo\">https://github.com/gohugoio/hugo</a></p>\n<h2>Go</h2>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">sudo add-apt-repository ppa:longsleep/golang-backports\nsudo apt update\nsudo apt install golang-go</code></pre></div>\n<h2>Hugo</h2>\n<p>注意：SCSSを使うには”Extended”版が必要</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">wget https://github.com/gohugoio/hugo/releases/download/v0.69.0/hugo_extended_0.69.0_Linux-64bit.deb\nsudo dpkg -i hugo_extended_0.69.0_Linux-64bit.deb</code></pre></div>\n<h2>GitHook</h2>\n<p>/var/www/html/git/blog.git/hooks/post-receive を作成</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">#!/bin/bash\nexport GIT_WORK_TREE=/var/www/html/blog\ncd $GIT_WORK_TREE\nunset GIT_DIR\ngit pull\nhugo</code></pre></div>\n<p>bash /var/www/html/git/blog.git/hooks/post-receive\nで動作確認</p>\n<h2>Hugo Nginx</h2>\n<p>/etc/nginx/sites-available/default を編集する。</p>\n<h2>Isso Nginx</h2>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">        location /isso {\n                proxy_set_header Host $http_host;\n                proxy_set_header X-Real-IP $remote_addr;\n                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n                proxy_set_header X-Forwarded-Proto $scheme;\n                proxy_pass http://localhost:8181/;\n        }</code></pre></div>","id":"54bfbf61-0cd0-5fcd-a821-d6675cf7454f","frontmatter":{"title":"Hugo","date":"April 11, 2020","tags":["webapp","日本語"]},"fields":{"slug":"/Japanese/webapp/Hugo/"}}},{"node":{"excerpt":"Algohttps://github.com/trailofbits/algo","html":"<h2>Algo</h2>\n<p><a href=\"https://github.com/trailofbits/algo\">https://github.com/trailofbits/algo</a></p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">python3 -m pip install --upgrade virtualenv</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">git clone https://github.com/trailofbits/algo.git\ncd algo</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">python3 -m virtualenv --python=&quot;$(command -v python3)&quot; .env &amp;&amp;\n  source .env/bin/activate &amp;&amp;\n  python3 -m pip install -U pip virtualenv &amp;&amp;\n  python3 -m pip install -r requirements.txt</code></pre></div>","id":"79bc4ada-62fc-5135-81a7-c845062938c3","frontmatter":{"title":"VPNサーバー","date":"April 11, 2020","tags":["webapp","日本語"]},"fields":{"slug":"/Japanese/webapp/VPNサーバー/"}}},{"node":{"excerpt":"音声合成ツールについての解説。動画中の音声はこのツールによって作成しています。こんにちは、TOMOです。最近テキスト読み上げツールを開発しています。\n今のところ日本語と中国語が読めるようになりました。\n英語は研究データも多く難易度が低いのでこれも追加する予定です。\nYoutube…","html":"<p>音声合成ツールについての解説。動画中の音声はこのツールによって作成しています。</p>\n\n          <div\n            class=\"gatsby-resp-iframe-wrapper\"\n            style=\"padding-bottom: 56.25%; position: relative; height: 0; overflow: hidden;\"\n          >\n            <iframe src=\"https://www.youtube.com/embed/Nli9Wx7r5ZI\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen style=\"\n            position: absolute;\n            top: 0;\n            left: 0;\n            width: 100%;\n            height: 100%;\n          \"></iframe>\n          </div>\n          \n<p>こんにちは、TOMOです。</p>\n<p>最近テキスト読み上げツールを開発しています。\n今のところ日本語と中国語が読めるようになりました。\n英語は研究データも多く難易度が低いのでこれも追加する予定です。\nYoutubeにデモ動画をあげてあるので、よろしければ見てください。\nプロトタイプの段階ですが、とりあえず使い物になるものができたと思います。</p>\n<p>私は普段は画像処理系の仕事をすることが多いです。\n最近テキスト関係の開発を始めて、今一か月ぐらいです。\n一昔前までは個人で音声合成が開発できるなどとは想像もしなかったのですが、良い時代になりました。\n今日は音声合成の仕組みだとか応用に関して話をします。\n動画の構成としては、前半部分は音声処理でどんなことができるか、後半部分は音声合成に関する理論的な話となります。</p>\n<p>音声処理のディープラーニングを使って何ができるかというと、\nまず第一に語学学習、他には動画作成などにも応用できます。</p>\n<p>昔は本を使って語学を勉強するのが主流で、日本人は英語の読み書きはできても話すことができないということがありました。\nCDが普及すると聞き取りの勉強が手軽にできるようになりました。\nただ、教科書の例文やオーディオブックなどは音声があるわけですが、自分の読みたい文章に音声がついているということはあまりなかったわけです。\nこれが音声読み上げの技術を使うと好きな文章を発声させることができます。\n実際この辺りは十年ぐらい前でもそれなりの事ができました。\n私が語学を勉強したときは基本的に全ての文章をプログラムに発声させていました。</p>\n<p>最近は人工知能や音声認識部分も発達してきているので、\n人工知能を使って発音矯正や対話練習などもできるようにしたいと考えています。\n自分の外国語の発音がどこが悪いかというのは一人ではよくわからないわけです。\nここを人工知能によって発音を採点して数字で表したら、一人でもどう発音を直していったら良いかわかるわけです。\nさらに音声読み上げ技術を使って、自分の声でネイティブの発音の例文を作ったら\nもっと発音の違いが分かりやすいんじゃないかと思っています。\n一昔の技術は大体録音した音声を上手くつなぎ合わせるような感じの手法なので、録音した人の声しか出せません。\n最近はTacotronなどにもスタイルトークンというようなものを使って、複数の人間の声を生成するようなことができるようになっています。\nそういう技術を使えば、教科書の例文に自分の声をまねさせるといったことができるということになります。</p>\n<p>次に動画作成に関しては、文字を読ませてテキストを動画に変換するというのはまず基本的な使い方です。\n移動中に本を読むなどしたいとき、音声があると色々と便利なわけです。\n他には外国語の文章を読むときなんかもやっぱり音声があると読みやすいということがあります。\nこういう事があるので自動でテキストを動画に変換するようなツールが欲しいなと思うわけです。\nこの辺りのツールの作成部分はディープラーニングというよりも普通のプログラミングがメインになります。\nディープラーニングにおける技術的な問題としては、\n本を読ませると日本語と英語が混ざっている文なんかは結構出てくるわけです。\n技術的にはこういうところの処理を上手くやらないといけません。</p>\n<p>あと、Youtubeなんかで動画をあげてみると分かるのですが、字幕を付けるというのは結構面倒な作業です。\n色々と自動でやってくれるツールがあるわけですが、\n英語や中国語だと音声から文字というのはある程度正確にできるのですが、日本語は誤変換が多いです。\nまた、字幕を装飾して動画に埋め込むには動画編集ツールを使わないといけないので、\n色々なツールが必要となって制作の流れがかなり煩雑になります。\nこの辺りをもう少し簡略化したいと考えています。\n日本語の誤変換が多いのはどうしようもないところがあるので、事前にスクリプトだけは準備して、\nドラッグアンドドロップしたら音声認識で自動で時間をあわせて動画への字幕の埋め込みまでできるようにしたいです。</p>\n<p>ここから音声合成の理論的な話に入ります。</p>\n<p>音声合成の基本的なモジュールは次の三つになります。</p>\n<ul>\n<li>テキスト解析 ： テキストを言語特徴量に変換</li>\n<li>音響モデル：言語特徴量を音響特徴量に変換</li>\n<li>ボコーダー：音響特徴量を実際の音声に変換</li>\n</ul>\n<p>テキスト解析の部分はフロントエンドなどとも呼ばれます。</p>\n<hr>\n<h1>日本語音声合成</h1>\n<p>日本語の音声合成はまだ一昔前の技術が主流らしいです。</p>\n<p>少なくとも<t>Github</t><v>ギットハブ</v>などでは基本的に英語で、中国語も少しあります。</p>\n<p>一つの問題は文字と音声の関係性にあると思われます。</p>\n<hr>\n<h1><t>日本語音声合成</t></h1>\n<p>英語や中国語は文字と発音が基本的に一対一に対応しています。</p>\n<p>知らない単語でも文字を見れば大体読み方は想像できます。</p>\n<p>それに対し、日本語では特に人名地名など、読み方を覚えていなければ発音が想像できない場合が多々あります。</p>\n<p>そのため、日本語は音声合成が最も難しい言語の一つと考えられます。</p>\n<hr>\n<p><img src=\"2020-04-24-15-16-52.png\">\n<t><a href=\"https://www.slideshare.net/f2forest/nips2017-speech-audio-86474213\">https://www.slideshare.net/f2forest/nips2017-speech-audio-86474213</a></t></p>\n<hr>\n<p>ディープラーニングでは人の手で特徴量を作らず、データから特徴量を学習させます。</p>\n<p>従来では人の手で生成していた言語特徴量・音響特徴量を機械学習によって生成します。</p>\n<p>これは音声合成に限らず、画像認識等の分野でも同様です。</p>\n<hr>\n<h1>今回使った仕組み</h1>\n<ul>\n<li>\n<p>音声データ: JSUT</p>\n</li>\n<li>\n<p>テキスト解析：<t>Mecab</t><v>メカブ</v></p>\n</li>\n<li>\n<p>音響モデル: <t>Tensorflow</t><v>テンサーフロー</v></p>\n</li>\n<li>\n<p>ボコーダー: <t>World</t><v>ワールド</v></p>\n</li>\n</ul>\n<hr>\n<h1>音声データ</h1>\n<p>JSUTとは、東京大学猿渡研究室による日本語女性話者の約10時間の音声です。</p>\n<p>無音カット、音素アラインメントといった前処理はせず、直接学習させます。</p>\n<p>今後の予定として、使用者の声を直接学習させるといったことをしたいので、複雑な前処理は不要なシステムにします。</p>\n<p><t>Ryosuke Sonobe, Shinnosuke Takamichi and Hiroshi Saruwatari,  \"JSUT corpus: free large-scale Japanese speech corpus for end-to-end speech synthesis,\" arXiv preprint, 1711.00354, 2017.</t></p>\n<hr>\n<h1>テキスト解析</h1>\n<p>漢字の読み方をJSUTだけで<t>EndToEnd</t><v>エンドトゥーエンド</v>に覚えさせるのはデータ量的に厳しいです。</p>\n<p>そのため、単語辞書を使って形態素解析ということを行い音素列を生成します。</p>\n<p>漢字をローマ字に置き換えるような感じです。</p>\n<p>また、日本語には橋と箸と言った音の高さで区別される単語があるので、高低アクセントも付与します。</p>\n<p>機会があればこの辺りもディープラーニングを使いたいところです。</p>\n<hr>\n<h1><t>テキスト解析</t></h1>\n<p>実は今のところこの音声合成ツールは英語が読めません。</p>\n<p>そのため英語の部分にはルビを振って読ませています。</p>\n<p>後ほど英語を読む機能を追加したいところです。</p>\n<hr>\n<h1>音響モデル</h1>\n<p>テキスト解析によって生成された音素列をスペクトログラムと呼ばれる音響特徴量に変換します。</p>\n<p>スペクトログラムというのは音声の各周波数の強さを表したものです。</p>\n<p>正確には<t>World</t><v>ワールド</v>ボコーダーを使っているので、スペクトログラムを直接使うわけではありません。</p>\n<p><img src=\"2020-04-24-15-44-48.png\"></p>\n<hr>\n<h1><t>音響モデル</t></h1>\n<p>音響モデルは音素列を音響特徴量に変換します。</p>\n<p>このような処理には<t>Seq2Seq</t><v>シークエンストゥーシークエンス</v>と呼ばれるRNNモデルを使うことが多いです。</p>\n<p>ただ、この方法の欠点として訓練に時間がかかる、訓練データが悪いとそもそも学習できないという点があります。</p>\n<p><t>Tacotron</t><v>タコトロン</v>などではアラインメントが上手く学習できないということもよく聞きます。</p>\n<hr>\n<h1><t>音響モデル</t></h1>\n<p>そういうわけで、今回は単純に音響モデルには一次元CNNによるオートエンコーダーを使います。</p>\n<p>スペクトログラムを入力し、音素列にエンコード、さらにスペクトログラムへデコードします。</p>\n<p>デコードの部分が実際に使う音響モデルです。</p>\n<p>オートエンコーダーは収束も早く、訓練も安定しているので、画像処理でもよく使いました。</p>\n<p>ついでに<t>GAN</t><v>ガン</v>も使っています。</p>\n<hr>\n<h1><t>オートエンコーダ</t></h1>\n<p><img src=\"2020-04-24-16-30-30.png\"></p>\n<hr>\n<h1>ボコーダー</h1>\n<p>ボコーダーを使ってスペクトログラムを波形データに戻します。</p>\n<p>今回は簡単のため<t>World</t><v>ワールド</v>ボコーダーをそのまま使っています。</p>\n<p>理想的にはここもディープラーニングを使いたいところです。</p>\n<p>ボコーダー部分は話者依存、言語依存が低いので、英語データで訓練した物を流用できると思われます。</p>\n<p>ディープラーニングにおいてデータの不足は致命的なので、今後このような方法を検討する予定です。</p>\n<hr>\n<h1>今後の予定</h1>\n<ul>\n<li>\n<p>スライダーで声質を調整できるようにする</p>\n</li>\n<li>\n<p>文字から音声の変換だけでなく、自分の声を他の人の声にすると言った声質変換をする</p>\n</li>\n<li>\n<p>テキスト解析にディープラーニングを利用、英語を読めるようにする</p>\n</li>\n<li>\n<p><t>Tacotron/Wavenet</t><v>タコトロン、ウェーブネット</v>のような訓練に時間が掛かる機構も導入</p>\n</li>\n</ul>\n<blockquote>\n<blockquote>\n<blockquote>\n</blockquote>\n</blockquote>\n</blockquote>\n<h1>おしまい</h1>\n<p>ご視聴ありがとうございました。</p>\n<p>何かあればコメント欄にお願いします。</p>\n<p>需要があればツールの公開もする予定です。</p>","id":"2d65c1b7-f1b5-5573-8436-82c78e3f6e85","frontmatter":{"title":"自作音声合成ツール解説","date":"April 09, 2020","tags":["日本語","tensorflow","音声処理","Featured"]},"fields":{"slug":"/Japanese/TomoSpeech/"}}},{"node":{"excerpt":"Jupyterのおまじない画像表示","html":"<h2>Jupyterのおまじない</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token operator\">%</span>load_ext autoreload\n<span class=\"token operator\">%</span>autoreload <span class=\"token number\">2</span>\n<span class=\"token operator\">%</span>matplotlib inline</code></pre></div>\n<h2>画像表示</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\n\nplt<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span>img<span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>","id":"30fa645f-e12c-563d-a0c8-f033df845c41","frontmatter":{"title":"Matplotlib","date":"April 01, 2020","tags":["python","日本語"]},"fields":{"slug":"/Japanese/python/共通1/"}}},{"node":{"excerpt":"ファイル読み込み行ごとにリストに変換ファイル書き込み","html":"<h2>ファイル読み込み</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> io\nf <span class=\"token operator\">=</span> io<span class=\"token punctuation\">.</span><span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>readpath<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> mode<span class=\"token operator\">=</span><span class=\"token string\">\"r\"</span><span class=\"token punctuation\">,</span> encoding<span class=\"token operator\">=</span><span class=\"token string\">\"utf-8\"</span><span class=\"token punctuation\">)</span>\nstrs <span class=\"token operator\">=</span> f<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nf<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h2>行ごとにリストに変換</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">lines <span class=\"token operator\">=</span> strs<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h2>ファイル書き込み</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">f <span class=\"token operator\">=</span> io<span class=\"token punctuation\">.</span><span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>writepath<span class=\"token punctuation\">,</span> mode<span class=\"token operator\">=</span><span class=\"token string\">\"w\"</span><span class=\"token punctuation\">,</span> encoding<span class=\"token operator\">=</span><span class=\"token string\">\"utf-8\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">for</span> line <span class=\"token keyword\">in</span> lines<span class=\"token punctuation\">:</span>\n    f<span class=\"token punctuation\">.</span>writelines<span class=\"token punctuation\">(</span>line <span class=\"token operator\">+</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">)</span>\nf<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>","id":"372de5da-ace4-5fb6-ad66-617c538b78ea","frontmatter":{"title":"テキストファイル処理","date":"April 01, 2020","tags":["言語解析","python","日本語"]},"fields":{"slug":"/Japanese/python/Text Analysis/テキスト処理1/"}}},{"node":{"excerpt":"カタカナを平仮名にするローマ字辞書cl, pauについてはJulius用 ","html":"<h2>カタカナを平仮名にする</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">ToHiragana</span><span class=\"token punctuation\">(</span>strj<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> <span class=\"token string\">\"\"</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token builtin\">chr</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">ord</span><span class=\"token punctuation\">(</span>ch<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> <span class=\"token number\">96</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token string\">\"ァ\"</span> <span class=\"token operator\">&lt;=</span> ch <span class=\"token operator\">&lt;=</span> <span class=\"token string\">\"ヴ\"</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">else</span> ch <span class=\"token keyword\">for</span> ch <span class=\"token keyword\">in</span> strj<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h2>ローマ字辞書</h2>\n<p>cl, pauについてはJulius用 </p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">ROMAJI <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n\n        <span class=\"token string\">'pau'</span><span class=\"token punctuation\">:</span><span class=\"token string\">\" \"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'ti'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'チ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'si'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'シ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'zi'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ジ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'cl'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ッ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'tsu'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ツ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'tsa'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ツァ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'tsi'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ツィ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'tse'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ツェ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'tso'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ツォ'</span><span class=\"token punctuation\">,</span>\n\n        <span class=\"token string\">'a'</span>  <span class=\"token punctuation\">:</span><span class=\"token string\">'ア'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'i'</span>  <span class=\"token punctuation\">:</span><span class=\"token string\">'イ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'u'</span>  <span class=\"token punctuation\">:</span><span class=\"token string\">'ウ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'e'</span>  <span class=\"token punctuation\">:</span><span class=\"token string\">'エ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'o'</span>  <span class=\"token punctuation\">:</span><span class=\"token string\">'オ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'ka'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'カ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ki'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'キ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ku'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ク'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ke'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ケ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ko'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'コ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'sa'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'サ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'shi'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'シ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'su'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ス'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'se'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'セ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'so'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ソ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'ta'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'タ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'chi'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'チ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'tu'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ツ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'te'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'テ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'to'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ト'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'na'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ナ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ni'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ニ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'nu'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ヌ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ne'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ネ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'no'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ノ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'ha'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ハ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'hi'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ヒ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'fu'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'フ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'he'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ヘ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ho'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ホ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'ma'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'マ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'mi'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ミ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'mu'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ム'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'me'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'メ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'mo'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'モ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'ya'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ヤ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'yu'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ユ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'yo'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ヨ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'ra'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ラ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ri'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'リ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ru'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ル'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'re'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'レ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ro'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ロ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'wa'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ワ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'wo'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ヲ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'n'</span>  <span class=\"token punctuation\">:</span><span class=\"token string\">'ン'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'vu'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ヴ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'ga'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ガ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'gi'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ギ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'gu'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'グ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ge'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ゲ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'go'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ゴ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'za'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ザ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ji'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ジ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'zu'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ズ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ze'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ゼ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'zo'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ゾ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'da'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ダ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'di'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ヂ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'du'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ヅ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'de'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'デ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'do'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ド'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'ba'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'バ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'bi'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ビ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'bu'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ブ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'be'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ベ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'bo'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ボ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'pa'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'パ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'pi'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ピ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'pu'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'プ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'pe'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ペ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'po'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ポ'</span><span class=\"token punctuation\">,</span>\n        \n        <span class=\"token string\">'kya'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'キャ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'kyi'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'キィ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'kyu'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'キュ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'kye'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'キェ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'kyo'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'キョ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'gya'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ギャ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'gyi'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ギィ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'gyu'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ギュ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'gye'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ギェ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'gyo'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ギョ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'sha'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'シャ'</span><span class=\"token punctuation\">,</span>               <span class=\"token string\">'shu'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'シュ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'she'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'シェ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'sho'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ショ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'ja'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ジャ'</span><span class=\"token punctuation\">,</span>               <span class=\"token string\">'ju'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ジュ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'je'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ジェ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'jo'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ジョ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'cha'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'チャ'</span><span class=\"token punctuation\">,</span>               <span class=\"token string\">'chu'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'チュ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'che'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'チェ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'cho'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'チョ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'dya'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ヂャ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'dyi'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ヂィ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'dyu'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ヂュ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'dhe'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'デェ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'dyo'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ヂョ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'nya'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ニャ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'nyi'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ニィ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'nyu'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ニュ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'nye'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ニェ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'nyo'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ニョ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'hya'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ヒャ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'hyi'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ヒィ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'hyu'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ヒュ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'hye'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ヒェ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'hyo'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ヒョ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'bya'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ビャ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'byi'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ビィ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'byu'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ビュ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'bye'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ビェ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'byo'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ビョ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'pya'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ピャ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'pyi'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ピィ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'pyu'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ピュ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'pye'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ピェ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'pyo'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ピョ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'mya'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ミャ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'myi'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ミィ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'myu'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ミュ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'mye'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ミェ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'myo'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ミョ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'rya'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'リャ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ryi'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'リィ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ryu'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'リュ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'rye'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'リェ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ryo'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'リョ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'fa'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ファ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'fi'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'フィ'</span><span class=\"token punctuation\">,</span>               <span class=\"token string\">'fe'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'フェ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'fo'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'フォ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'wi'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ウィ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'we'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ウェ'</span><span class=\"token punctuation\">,</span> \n        <span class=\"token string\">'va'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ヴァ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'vi'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ヴィ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ve'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ヴェ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'vo'</span> <span class=\"token punctuation\">:</span><span class=\"token string\">'ヴォ'</span><span class=\"token punctuation\">,</span>\n        \n        <span class=\"token string\">'kwa'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'クァ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'kwi'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'クィ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'kwu'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'クゥ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'kwe'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'クェ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'kwo'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'クォ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'kha'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'クァ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'khi'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'クィ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'khu'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'クゥ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'khe'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'クェ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'kho'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'クォ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'gwa'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'グァ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'gwi'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'グィ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'gwu'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'グゥ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'gwe'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'グェ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'gwo'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'グォ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'gha'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'グァ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ghi'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'グィ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ghu'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'グゥ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ghe'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'グェ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'gho'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'グォ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'swa'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'スァ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'swi'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'スィ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'swu'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'スゥ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'swe'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'スェ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'swo'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'スォ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'swa'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'スァ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'swi'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'スィ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'swu'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'スゥ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'swe'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'スェ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'swo'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'スォ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'zwa'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ズヮ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'zwi'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ズィ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'zwu'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ズゥ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'zwe'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ズェ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'zwo'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ズォ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'twa'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'トァ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'twi'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'トィ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'twu'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'トゥ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'twe'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'トェ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'two'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'トォ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'dwa'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ドァ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'dwi'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ドィ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'dwu'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ドゥ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'dwe'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ドェ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'dwo'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ドォ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'mwa'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ムヮ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'mwi'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ムィ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'mwu'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ムゥ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'mwe'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ムェ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'mwo'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ムォ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'bwa'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ビヮ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'bwi'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ビィ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'bwu'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ビゥ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'bwe'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ビェ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'bwo'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'ビォ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'pwa'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'プヮ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'pwi'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'プィ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'pwu'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'プゥ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'pwe'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'プェ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'pwo'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'プォ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'phi'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'プィ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'phu'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'プゥ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'phe'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'プェ'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'pho'</span><span class=\"token punctuation\">:</span><span class=\"token string\">'フォ'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token punctuation\">}</span></code></pre></div>","id":"414bfa88-43ea-5e68-8910-5640dae70b24","frontmatter":{"title":"ローマ字・ひらがな・カタカナ 変換","date":"April 01, 2020","tags":["言語解析","python","日本語"]},"fields":{"slug":"/Japanese/python/Text Analysis/テキスト処理3/"}}},{"node":{"excerpt":"Wav・Oggファイル読み込みOggにはコーデックのインストールが必要。FFMpegを使う。","html":"<h2>Wav・Oggファイル読み込み</h2>\n<p>Oggにはコーデックのインストールが必要。FFMpegを使う。</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> librosa\nJPSR <span class=\"token operator\">=</span> <span class=\"token number\">16000</span>\npath <span class=\"token operator\">=</span> <span class=\"token string\">r\"test.ogg\"</span>\ny<span class=\"token punctuation\">,</span> sr <span class=\"token operator\">=</span> librosa<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span>path<span class=\"token punctuation\">,</span> sr<span class=\"token operator\">=</span>JPSR<span class=\"token punctuation\">,</span> duration<span class=\"token operator\">=</span><span class=\"token number\">100000</span><span class=\"token punctuation\">)</span></code></pre></div>","id":"d472be6e-bd03-5c1c-9909-257c7f5640cb","frontmatter":{"title":"Librosa","date":"April 01, 2020","tags":["音声処理","python","日本語"]},"fields":{"slug":"/Japanese/python/Sound Processing/音声処理1/"}}},{"node":{"excerpt":"形態素解析。主に漢字を読み仮名に変換する際に用いる。Mecab","html":"<p>形態素解析。主に漢字を読み仮名に変換する際に用いる。</p>\n<h2>Mecab</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> MeCab\n\nmecab <span class=\"token operator\">=</span> MeCab<span class=\"token punctuation\">.</span>Tagger<span class=\"token punctuation\">(</span><span class=\"token string\">'-Oyomi'</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">MecabParse</span><span class=\"token punctuation\">(</span>txt<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    res <span class=\"token operator\">=</span> mecab<span class=\"token punctuation\">.</span>parse<span class=\"token punctuation\">(</span>txt<span class=\"token punctuation\">)</span>\n    res <span class=\"token operator\">=</span> res<span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"\"</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> res\nMecabParse<span class=\"token punctuation\">(</span><span class=\"token string\">\"「名前的になんとなくオチがわかる」\"</span><span class=\"token punctuation\">)</span></code></pre></div>","id":"375fb91e-1221-5ba8-8c0e-7755fe1b3f5b","frontmatter":{"title":"MECAB","date":"April 01, 2020","tags":["言語解析","python","日本語"]},"fields":{"slug":"/Japanese/python/Text Analysis/テキスト処理2/"}}},{"node":{"excerpt":"メモリ上の音声再生音声ファイル再生","html":"<h2>メモリ上の音声再生</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> sounddevice <span class=\"token keyword\">as</span> sd\n<span class=\"token keyword\">def</span> <span class=\"token function\">Play</span><span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">,</span> sr<span class=\"token operator\">=</span><span class=\"token number\">16000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    sd<span class=\"token punctuation\">.</span>play<span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">,</span> sr<span class=\"token punctuation\">)</span>\n    sd<span class=\"token punctuation\">.</span>wait<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h2>音声ファイル再生</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> sounddevice <span class=\"token keyword\">as</span> sd\n<span class=\"token keyword\">import</span> librosa\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">Play</span><span class=\"token punctuation\">(</span>path<span class=\"token punctuation\">,</span> SR<span class=\"token operator\">=</span><span class=\"token number\">16000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    y<span class=\"token punctuation\">,</span> sr <span class=\"token operator\">=</span> librosa<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span>path<span class=\"token punctuation\">,</span> sr<span class=\"token operator\">=</span>SR<span class=\"token punctuation\">,</span> duration<span class=\"token operator\">=</span><span class=\"token number\">100000</span><span class=\"token punctuation\">)</span>\n    sd<span class=\"token punctuation\">.</span>play<span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">,</span> sr<span class=\"token punctuation\">)</span>\n    sd<span class=\"token punctuation\">.</span>wait<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>","id":"8f20f325-8844-5ead-8726-bdba563dc7c0","frontmatter":{"title":"テキストファイル処理","date":"April 01, 2020","tags":["音声処理","python","日本語"]},"fields":{"slug":"/Japanese/python/Sound Processing/音声処理2/"}}},{"node":{"excerpt":"TensorflowでMelSpectrogramtf.signal.stftはTFLiteで使えない。","html":"<h2>TensorflowでMelSpectrogram</h2>\n<p>tf.signal.stftはTFLiteで使えない。</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">import</span> librosa\n<span class=\"token keyword\">import</span> librosa<span class=\"token punctuation\">.</span>display\n<span class=\"token keyword\">import</span> cv2\n\n<span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">MinMaxNorm</span><span class=\"token punctuation\">(</span>tensor<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    minval <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>reduce_min<span class=\"token punctuation\">(</span>tensor<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    maxval <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>reduce_max<span class=\"token punctuation\">(</span>tensor<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    \n    <span class=\"token keyword\">if</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">:</span>\n        maxval <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>maximum<span class=\"token punctuation\">(</span><span class=\"token number\">2.0</span><span class=\"token punctuation\">,</span> maxval<span class=\"token punctuation\">)</span>\n\n    tensor <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>divide<span class=\"token punctuation\">(</span>tensor <span class=\"token operator\">-</span> minval<span class=\"token punctuation\">,</span> maxval <span class=\"token operator\">-</span> minval <span class=\"token operator\">+</span> <span class=\"token number\">1e</span><span class=\"token operator\">-</span><span class=\"token number\">8</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> tensor\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">ToMelTF0</span><span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">,</span> sr<span class=\"token punctuation\">,</span> DIM<span class=\"token operator\">=</span><span class=\"token number\">128</span><span class=\"token punctuation\">,</span> TFLITE<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    batch_size<span class=\"token punctuation\">,</span> num_samples<span class=\"token punctuation\">,</span> sample_rate <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> sr\n\n    <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> TFLITE<span class=\"token punctuation\">:</span>\n        <span class=\"token comment\"># A 1024-point STFT with frames of 64 ms and 75% overlap.</span>\n        stfts <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>signal<span class=\"token punctuation\">.</span>stft<span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">,</span> frame_length<span class=\"token operator\">=</span><span class=\"token number\">1024</span><span class=\"token punctuation\">,</span> frame_step<span class=\"token operator\">=</span><span class=\"token number\">256</span><span class=\"token punctuation\">,</span>\n                            fft_length<span class=\"token operator\">=</span><span class=\"token number\">1024</span><span class=\"token punctuation\">,</span> pad_end<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\n\n        spectrograms <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span><span class=\"token builtin\">abs</span><span class=\"token punctuation\">(</span>stfts<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n        y <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        spectrograms<span class=\"token punctuation\">,</span> stfts <span class=\"token operator\">=</span> stft_magnitude_tflite<span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">,</span> window_length_samples<span class=\"token operator\">=</span><span class=\"token number\">1024</span><span class=\"token punctuation\">,</span>hop_length_samples<span class=\"token operator\">=</span><span class=\"token number\">256</span><span class=\"token punctuation\">,</span>fft_length<span class=\"token operator\">=</span><span class=\"token number\">1024</span><span class=\"token punctuation\">)</span>\n        \n    <span class=\"token comment\"># Warp the linear scale spectrograms into the mel-scale.</span>\n    num_spectrogram_bins <span class=\"token operator\">=</span> stfts<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token comment\">#.value</span>\n    lower_edge_hertz<span class=\"token punctuation\">,</span> upper_edge_hertz<span class=\"token punctuation\">,</span> num_mel_bins <span class=\"token operator\">=</span> <span class=\"token number\">80.0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">7600.0</span><span class=\"token punctuation\">,</span> DIM\n    linear_to_mel_weight_matrix <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>signal<span class=\"token punctuation\">.</span>linear_to_mel_weight_matrix<span class=\"token punctuation\">(</span>\n    num_mel_bins<span class=\"token punctuation\">,</span> num_spectrogram_bins<span class=\"token punctuation\">,</span> sample_rate<span class=\"token punctuation\">,</span> lower_edge_hertz<span class=\"token punctuation\">,</span>\n    upper_edge_hertz<span class=\"token punctuation\">)</span>\n    mel_spectrograms <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>tensordot<span class=\"token punctuation\">(</span>\n    spectrograms<span class=\"token punctuation\">,</span> linear_to_mel_weight_matrix<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n\n    mel_spectrograms<span class=\"token punctuation\">.</span>set_shape<span class=\"token punctuation\">(</span>spectrograms<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>concatenate<span class=\"token punctuation\">(</span>\n    linear_to_mel_weight_matrix<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Compute a stabilized log to get log-magnitude mel-scale spectrograms.</span>\n    log_mel_spectrograms <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>math<span class=\"token punctuation\">.</span>log<span class=\"token punctuation\">(</span>mel_spectrograms <span class=\"token operator\">+</span> <span class=\"token number\">1e</span><span class=\"token operator\">-</span><span class=\"token number\">6</span><span class=\"token punctuation\">)</span>\n    log_mel_spectrograms <span class=\"token operator\">=</span> MinMaxNorm<span class=\"token punctuation\">(</span>log_mel_spectrograms<span class=\"token punctuation\">)</span>\n    \n    <span class=\"token keyword\">return</span> log_mel_spectrograms\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">ToMelTF</span><span class=\"token punctuation\">(</span>filename<span class=\"token punctuation\">,</span> sr<span class=\"token operator\">=</span><span class=\"token number\">16000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n    y<span class=\"token punctuation\">,</span> sr <span class=\"token operator\">=</span> librosa<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span>filename<span class=\"token punctuation\">,</span> sr<span class=\"token operator\">=</span>sr<span class=\"token punctuation\">,</span> duration<span class=\"token operator\">=</span><span class=\"token number\">100000</span><span class=\"token punctuation\">)</span>\n    log_mel_spectrograms <span class=\"token operator\">=</span>ToMelTF0<span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">[</span>np<span class=\"token punctuation\">.</span>newaxis<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> sr<span class=\"token punctuation\">)</span>\n    res <span class=\"token operator\">=</span> log_mel_spectrograms<span class=\"token punctuation\">.</span>numpy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">return</span> res</code></pre></div>","id":"6452f1ea-5f69-51d2-9212-9f9c976e2288","frontmatter":{"title":"Tensorflowで音声処理","date":"April 01, 2020","tags":["音声処理","python","日本語"]},"fields":{"slug":"/Japanese/python/Sound Processing/音声処理3/"}}},{"node":{"excerpt":"Pyworldは音声を基本周波数、スペクトログラム、非周期成分に分解、再合成できる。基本周波数の抽出にはharvestとdioがある。harvestの方がノイズが少ない感じ。分解再合成Example","html":"<p>Pyworldは音声を基本周波数、スペクトログラム、非周期成分に分解、再合成できる。</p>\n<p>基本周波数の抽出にはharvestとdioがある。harvestの方がノイズが少ない感じ。</p>\n<h2>分解</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> scipy<span class=\"token punctuation\">.</span>io <span class=\"token keyword\">import</span> wavfile\n<span class=\"token keyword\">import</span> pyworld\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\nWAV_FILE <span class=\"token operator\">=</span> <span class=\"token string\">'Tomo.wav'</span>\n\nfs<span class=\"token punctuation\">,</span> data <span class=\"token operator\">=</span> wavfile<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span>WAV_FILE<span class=\"token punctuation\">)</span>\ndata <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span><span class=\"token builtin\">float</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># Floatに変換が必要</span>\n\n_f0<span class=\"token punctuation\">,</span> t <span class=\"token operator\">=</span> pyworld<span class=\"token punctuation\">.</span>harvest<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">,</span> fs<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 基本周波数の抽出</span>\nf0 <span class=\"token operator\">=</span> pyworld<span class=\"token punctuation\">.</span>stonemask<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">,</span> _f0<span class=\"token punctuation\">,</span> t<span class=\"token punctuation\">,</span> fs<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 基本周波数の修正</span>\nsp <span class=\"token operator\">=</span> pyworld<span class=\"token punctuation\">.</span>cheaptrick<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">,</span> f0<span class=\"token punctuation\">,</span> t<span class=\"token punctuation\">,</span> fs<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># スペクトル包絡の抽出</span>\nap <span class=\"token operator\">=</span> pyworld<span class=\"token punctuation\">.</span>d4c<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">,</span> f0<span class=\"token punctuation\">,</span> t<span class=\"token punctuation\">,</span> fs<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 非周期性指標の抽出</span></code></pre></div>\n<h2>再合成</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">synthesized <span class=\"token operator\">=</span> pyworld<span class=\"token punctuation\">.</span>synthesize<span class=\"token punctuation\">(</span>f0<span class=\"token punctuation\">,</span> sp<span class=\"token punctuation\">,</span> ap<span class=\"token punctuation\">,</span> fs<span class=\"token punctuation\">)</span></code></pre></div>\n<h2>Example</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> librosa\n<span class=\"token keyword\">import</span> pyworld <span class=\"token keyword\">as</span> pw\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">import</span> sounddevice <span class=\"token keyword\">as</span> sd\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\n<span class=\"token keyword\">import</span> pysptk\n<span class=\"token keyword\">import</span> pyworld\n<span class=\"token keyword\">from</span> pysptk<span class=\"token punctuation\">.</span>conversion <span class=\"token keyword\">import</span> sp2mc<span class=\"token punctuation\">,</span> mc2sp\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">Play</span><span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">,</span> sr<span class=\"token operator\">=</span><span class=\"token number\">16000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    sd<span class=\"token punctuation\">.</span>play<span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">,</span> sr<span class=\"token punctuation\">)</span>\n    sd<span class=\"token punctuation\">.</span>wait<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n\nWAV_FILE <span class=\"token operator\">=</span> <span class=\"token string\">'Tomo.wav'</span>\nSR <span class=\"token operator\">=</span> <span class=\"token number\">16000</span>\nfft_size <span class=\"token operator\">=</span> pyworld<span class=\"token punctuation\">.</span>get_cheaptrick_fft_size<span class=\"token punctuation\">(</span>SR<span class=\"token punctuation\">)</span>\nalpha <span class=\"token operator\">=</span> pysptk<span class=\"token punctuation\">.</span>util<span class=\"token punctuation\">.</span>mcepalpha<span class=\"token punctuation\">(</span>SR<span class=\"token punctuation\">)</span>\nmgc_dim <span class=\"token operator\">=</span> <span class=\"token number\">180</span>\n\ndata<span class=\"token punctuation\">,</span> sr <span class=\"token operator\">=</span> librosa<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span>WAV_FILE<span class=\"token punctuation\">,</span> sr<span class=\"token operator\">=</span>SR<span class=\"token punctuation\">,</span> duration<span class=\"token operator\">=</span><span class=\"token number\">100000</span><span class=\"token punctuation\">)</span>\ndata <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span><span class=\"token builtin\">float</span><span class=\"token punctuation\">)</span>  \n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">Encode</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">,</span> sr<span class=\"token operator\">=</span>SR<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    _f0<span class=\"token punctuation\">,</span> t <span class=\"token operator\">=</span> pyworld<span class=\"token punctuation\">.</span>harvest<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">,</span> sr<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 基本周波数の抽出</span>\n    f0 <span class=\"token operator\">=</span> pyworld<span class=\"token punctuation\">.</span>stonemask<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">,</span> _f0<span class=\"token punctuation\">,</span> t<span class=\"token punctuation\">,</span> sr<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 基本周波数の修正</span>\n    sp <span class=\"token operator\">=</span> pyworld<span class=\"token punctuation\">.</span>cheaptrick<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">,</span> f0<span class=\"token punctuation\">,</span> t<span class=\"token punctuation\">,</span> sr<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># スペクトル包絡の抽出</span>\n    ap <span class=\"token operator\">=</span> pyworld<span class=\"token punctuation\">.</span>d4c<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">,</span> f0<span class=\"token punctuation\">,</span> t<span class=\"token punctuation\">,</span> sr<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 非周期性指標の抽出</span>\n\n    mc <span class=\"token operator\">=</span> sp2mc<span class=\"token punctuation\">(</span>sp<span class=\"token punctuation\">,</span> mgc_dim<span class=\"token punctuation\">,</span> alpha<span class=\"token punctuation\">)</span>\n    cap <span class=\"token operator\">=</span> pyworld<span class=\"token punctuation\">.</span>code_aperiodicity<span class=\"token punctuation\">(</span>ap<span class=\"token punctuation\">,</span> sr<span class=\"token punctuation\">)</span>\n    f <span class=\"token operator\">=</span> f0 <span class=\"token operator\">/</span> <span class=\"token number\">512</span>\n\n    <span class=\"token keyword\">return</span> mc<span class=\"token punctuation\">,</span> cap<span class=\"token punctuation\">,</span> f\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">Decode</span><span class=\"token punctuation\">(</span>mc<span class=\"token punctuation\">,</span> cap<span class=\"token punctuation\">,</span> f<span class=\"token punctuation\">,</span> sr<span class=\"token operator\">=</span>SR<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n    f0 <span class=\"token operator\">=</span> f <span class=\"token operator\">*</span> <span class=\"token number\">512</span>\n    ap <span class=\"token operator\">=</span> pyworld<span class=\"token punctuation\">.</span>decode_aperiodicity<span class=\"token punctuation\">(</span>cap<span class=\"token punctuation\">,</span> sr<span class=\"token punctuation\">,</span> fft_size<span class=\"token punctuation\">)</span>\n    sp <span class=\"token operator\">=</span> mc2sp<span class=\"token punctuation\">(</span>mc<span class=\"token punctuation\">,</span> alpha<span class=\"token punctuation\">,</span> fft_size<span class=\"token punctuation\">)</span>\n\n    synthesized <span class=\"token operator\">=</span> pw<span class=\"token punctuation\">.</span>synthesize<span class=\"token punctuation\">(</span>f0 <span class=\"token punctuation\">,</span> sp<span class=\"token punctuation\">,</span> ap<span class=\"token punctuation\">,</span> sr<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> synthesized<span class=\"token punctuation\">,</span> f0<span class=\"token punctuation\">,</span> sp<span class=\"token punctuation\">,</span> ap\n\nmc<span class=\"token punctuation\">,</span> cap<span class=\"token punctuation\">,</span> f <span class=\"token operator\">=</span> Encode<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span>\nsynthesized<span class=\"token punctuation\">,</span> f0<span class=\"token punctuation\">,</span> sp<span class=\"token punctuation\">,</span> ap <span class=\"token operator\">=</span> Decode<span class=\"token punctuation\">(</span>mc<span class=\"token punctuation\">,</span> cap<span class=\"token punctuation\">,</span> f<span class=\"token punctuation\">)</span>\nPlay<span class=\"token punctuation\">(</span>synthesized<span class=\"token punctuation\">,</span> SR<span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>log<span class=\"token punctuation\">(</span>sp<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>colorbar<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>","id":"f397188a-e209-5372-85b8-c0e327146d2a","frontmatter":{"title":"Pyworld","date":"April 01, 2020","tags":["音声処理","python","日本語"]},"fields":{"slug":"/Japanese/python/Sound Processing/音声処理4/"}}},{"node":{"excerpt":"Tomohiro NagasakaEducation2004-2005 Kyoto University Undergraduate, Drop-out2009–2011  Kyoto University Master of Science (Math)2011-2013 Kyoto University Doctoral course, Drop…","html":"<h1>Tomohiro Nagasaka</h1>\n<h2>Education</h2>\n<ul>\n<li>2004-2005 Kyoto University Undergraduate, Drop-out</li>\n<li>2009–2011  Kyoto University Master of Science (Math)</li>\n<li>2011-2013 Kyoto University Doctoral course, Drop-out</li>\n</ul>\n<h2>Qualifications</h2>\n<p>International Mathematical Olympiad – Bronze Medal (2003)</p>\n<hr>\n<h1>Math</h1>\n<ul>\n<li>Algebraic Geometry</li>\n<li>Category Theory</li>\n<li>Algebraic Stacks</li>\n</ul>\n<h1>Computer Science</h1>\n<ul>\n<li>Image Processing</li>\n<li>Machine Learning</li>\n<li>Motion Capture</li>\n</ul>\n<h1>Programming Language</h1>\n<h3>Main</h3>\n<p>C++, Python, C#</p>\n<h3>Others</h3>\n<p>Javascript, Java, Kotlin, PHP, VB</p>\n<hr>\n<h1>Works</h1>\n<ul>\n<li>\n<p>GPU Object tracking/detection system for microscopic images (C++, CUDA, OpenCV)</p>\n</li>\n<li>\n<p>Automated warehouses control system (C, LINUX)</p>\n</li>\n<li>\n<p>Photo selection system with 2D/3D animation GUI (C#, WPF)</p>\n</li>\n<li>\n<p>Translation of a network textbook</p>\n</li>\n<li>\n<p>Geographical iOS/Web application (Objective-C, PHP, Database, WordPress, Google Map/ Twitter API)</p>\n</li>\n<li>\n<p>Web data management application development (C#, ASP.net, JavaScript, CSS, Amazon/Taobao API, etc.)</p>\n</li>\n<li>\n<p>VR Game development (UE4/Unity, Android)</p>\n</li>\n<li>\n<p>QR / Barcode Reader (C++, ARM)</p>\n</li>\n</ul>","id":"0d1307fa-0987-56cf-b934-0c4deda4950e","frontmatter":{"title":"About author","date":"December 14, 1985","tags":["English","About","Featured"]},"fields":{"slug":"/about/"}}}]}},"pageContext":{"isCreatedByStatefulCreatePages":true}}